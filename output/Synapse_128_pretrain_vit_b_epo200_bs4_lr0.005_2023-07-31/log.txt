[02:46:31.993] Namespace(AdamW=True, base_lr=0.005, batch_size=4, ckpt='checkpoints/sam_vit_b_01ec64.pth', dataset='Synapse', deterministic=1, dice_param=0.8, exp='Synapse_128', img_size=128, is_pretrain=True, list_dir='./lists/lists_PASTIS', lora_ckpt=None, max_epochs=200, max_iterations=30000, module='sam_lora_image_encoder', n_gpu=1, num_classes=20, num_workers=0, output='/home/narvjes/repos/SAMed-jnar/output', rank=4, root_path='/home/narvjes/data/PASTIS/SAMed', seed=1234, stop_epoch=200, vit_name='vit_b', warmup=True, warmup_period=250)
[02:46:31.997] 609 iterations per epoch. 121800 max iterations 
[02:46:32.134] iteration 1 : loss : 1.439608, loss_ce: 3.403358, loss_dice: 0.948670
[02:46:32.225] iteration 2 : loss : 1.386566, loss_ce: 3.189383, loss_dice: 0.935862
[02:46:32.309] iteration 3 : loss : 1.350676, loss_ce: 2.940877, loss_dice: 0.953126
[02:46:32.392] iteration 4 : loss : 1.317194, loss_ce: 2.745644, loss_dice: 0.960081
[02:46:32.478] iteration 5 : loss : 1.272020, loss_ce: 2.582395, loss_dice: 0.944426
[02:46:32.561] iteration 6 : loss : 1.254143, loss_ce: 2.491204, loss_dice: 0.944877
[02:46:32.645] iteration 7 : loss : 1.190672, loss_ce: 2.214000, loss_dice: 0.934840
[02:46:32.726] iteration 8 : loss : 1.199749, loss_ce: 2.263793, loss_dice: 0.933738
[02:46:32.808] iteration 9 : loss : 1.280138, loss_ce: 2.653522, loss_dice: 0.936792
[02:46:32.891] iteration 10 : loss : 1.238674, loss_ce: 2.472691, loss_dice: 0.930170
[02:46:32.977] iteration 11 : loss : 1.168598, loss_ce: 2.090955, loss_dice: 0.938009
[02:46:33.059] iteration 12 : loss : 1.174680, loss_ce: 2.171240, loss_dice: 0.925541
[02:46:33.142] iteration 13 : loss : 1.114125, loss_ce: 1.838523, loss_dice: 0.933026
[02:46:33.222] iteration 14 : loss : 1.179955, loss_ce: 2.159048, loss_dice: 0.935182
[02:46:33.301] iteration 15 : loss : 1.071558, loss_ce: 1.625094, loss_dice: 0.933174
[02:46:33.381] iteration 16 : loss : 1.170185, loss_ce: 2.042492, loss_dice: 0.952108
[02:46:33.460] iteration 17 : loss : 1.202097, loss_ce: 2.259811, loss_dice: 0.937669
[02:46:33.540] iteration 18 : loss : 1.210590, loss_ce: 2.293189, loss_dice: 0.939940
[02:46:33.621] iteration 19 : loss : 1.182792, loss_ce: 2.197770, loss_dice: 0.929047
[02:46:33.702] iteration 20 : loss : 1.178707, loss_ce: 2.173794, loss_dice: 0.929935
[02:46:33.797] iteration 21 : loss : 1.183289, loss_ce: 2.229432, loss_dice: 0.921753
[02:46:33.877] iteration 22 : loss : 1.224423, loss_ce: 2.424569, loss_dice: 0.924387
[02:46:33.958] iteration 23 : loss : 1.176449, loss_ce: 2.180841, loss_dice: 0.925351
[02:46:34.038] iteration 24 : loss : 1.195309, loss_ce: 2.276581, loss_dice: 0.924991
[02:46:34.116] iteration 25 : loss : 1.128345, loss_ce: 1.933792, loss_dice: 0.926984
[02:46:34.195] iteration 26 : loss : 1.180906, loss_ce: 2.191730, loss_dice: 0.928199
[02:46:34.275] iteration 27 : loss : 1.082272, loss_ce: 1.709180, loss_dice: 0.925545
[02:46:34.354] iteration 28 : loss : 0.987558, loss_ce: 1.230528, loss_dice: 0.926815
[02:46:34.434] iteration 29 : loss : 1.192810, loss_ce: 2.241998, loss_dice: 0.930512
[02:46:34.511] iteration 30 : loss : 1.253705, loss_ce: 2.683104, loss_dice: 0.896355
[02:46:34.589] iteration 31 : loss : 1.096565, loss_ce: 1.927132, loss_dice: 0.888923
[02:46:34.668] iteration 32 : loss : 1.126102, loss_ce: 2.289052, loss_dice: 0.835365
[02:46:34.750] iteration 33 : loss : 1.034290, loss_ce: 1.656374, loss_dice: 0.878769
[02:46:34.828] iteration 34 : loss : 1.250202, loss_ce: 2.695051, loss_dice: 0.888990
[02:46:34.907] iteration 35 : loss : 1.084748, loss_ce: 2.068574, loss_dice: 0.838792
[02:46:34.985] iteration 36 : loss : 1.077373, loss_ce: 2.043374, loss_dice: 0.835873
[02:46:35.065] iteration 37 : loss : 1.048798, loss_ce: 1.714702, loss_dice: 0.882322
[02:46:35.146] iteration 38 : loss : 1.067125, loss_ce: 1.993667, loss_dice: 0.835490
[02:46:35.227] iteration 39 : loss : 1.087816, loss_ce: 2.084076, loss_dice: 0.838750
[02:46:35.306] iteration 40 : loss : 1.129210, loss_ce: 2.319544, loss_dice: 0.831626
[02:46:35.394] iteration 41 : loss : 1.099416, loss_ce: 1.994243, loss_dice: 0.875710
[02:46:35.473] iteration 42 : loss : 1.173191, loss_ce: 2.523112, loss_dice: 0.835710
[02:46:35.550] iteration 43 : loss : 1.107848, loss_ce: 2.031657, loss_dice: 0.876895
[02:46:35.627] iteration 44 : loss : 1.013649, loss_ce: 1.707520, loss_dice: 0.840181
[02:46:35.709] iteration 45 : loss : 1.098607, loss_ce: 1.959258, loss_dice: 0.883444
[02:46:35.789] iteration 46 : loss : 1.253267, loss_ce: 2.675479, loss_dice: 0.897713
[02:46:35.870] iteration 47 : loss : 1.096596, loss_ce: 2.140447, loss_dice: 0.835634
[02:46:35.951] iteration 48 : loss : 1.055274, loss_ce: 1.765837, loss_dice: 0.877633
[02:46:36.032] iteration 49 : loss : 1.101948, loss_ce: 2.018998, loss_dice: 0.872686
[02:46:36.115] iteration 50 : loss : 1.073042, loss_ce: 2.032240, loss_dice: 0.833242
[02:46:36.197] iteration 51 : loss : 1.168781, loss_ce: 2.499668, loss_dice: 0.836059
[02:46:36.280] iteration 52 : loss : 1.124144, loss_ce: 2.088842, loss_dice: 0.882969
[02:46:36.362] iteration 53 : loss : 1.133909, loss_ce: 2.143182, loss_dice: 0.881591
[02:46:36.446] iteration 54 : loss : 1.021991, loss_ce: 1.782192, loss_dice: 0.831941
[02:46:36.531] iteration 55 : loss : 1.040226, loss_ce: 1.870150, loss_dice: 0.832745
[02:46:36.613] iteration 56 : loss : 1.142883, loss_ce: 2.342124, loss_dice: 0.843073
[02:46:36.695] iteration 57 : loss : 1.109934, loss_ce: 2.038300, loss_dice: 0.877843
[02:46:36.776] iteration 58 : loss : 1.076049, loss_ce: 1.845492, loss_dice: 0.883688
[02:46:36.858] iteration 59 : loss : 1.025611, loss_ce: 1.782873, loss_dice: 0.836296
[02:46:36.940] iteration 60 : loss : 1.048855, loss_ce: 1.917474, loss_dice: 0.831700
[02:46:37.027] iteration 61 : loss : 1.024891, loss_ce: 1.794897, loss_dice: 0.832390
[02:46:37.106] iteration 62 : loss : 1.107846, loss_ce: 2.031504, loss_dice: 0.876931
[02:46:37.184] iteration 63 : loss : 1.132160, loss_ce: 2.145623, loss_dice: 0.878794
[02:46:37.263] iteration 64 : loss : 1.116459, loss_ce: 2.067598, loss_dice: 0.878674
[02:46:37.341] iteration 65 : loss : 1.066567, loss_ce: 1.840178, loss_dice: 0.873165
[02:46:37.421] iteration 66 : loss : 1.046423, loss_ce: 1.910725, loss_dice: 0.830347
[02:46:37.501] iteration 67 : loss : 1.067819, loss_ce: 1.956763, loss_dice: 0.845582
[02:46:37.580] iteration 68 : loss : 1.033039, loss_ce: 1.863844, loss_dice: 0.825337
[02:46:37.660] iteration 69 : loss : 1.129853, loss_ce: 2.491030, loss_dice: 0.789558
[02:46:37.738] iteration 70 : loss : 1.119643, loss_ce: 2.464242, loss_dice: 0.783493
[02:46:37.816] iteration 71 : loss : 1.043309, loss_ce: 1.929981, loss_dice: 0.821641
[02:46:37.897] iteration 72 : loss : 1.139851, loss_ce: 2.180742, loss_dice: 0.879628
[02:46:37.977] iteration 73 : loss : 1.107485, loss_ce: 2.059724, loss_dice: 0.869425
[02:46:38.056] iteration 74 : loss : 1.229542, loss_ce: 2.837417, loss_dice: 0.827574
[02:46:38.135] iteration 75 : loss : 0.994300, loss_ce: 1.424138, loss_dice: 0.886841
[02:46:38.213] iteration 76 : loss : 1.044034, loss_ce: 1.873680, loss_dice: 0.836623
[02:46:38.294] iteration 77 : loss : 1.149569, loss_ce: 2.417504, loss_dice: 0.832585
[02:46:38.373] iteration 78 : loss : 0.976401, loss_ce: 1.477408, loss_dice: 0.851149
[02:46:38.453] iteration 79 : loss : 1.093268, loss_ce: 2.297891, loss_dice: 0.792113
[02:46:38.531] iteration 80 : loss : 1.102208, loss_ce: 2.195775, loss_dice: 0.828816
[02:46:38.620] iteration 81 : loss : 1.005101, loss_ce: 1.760939, loss_dice: 0.816141
[02:46:38.701] iteration 82 : loss : 1.082045, loss_ce: 2.109876, loss_dice: 0.825088
[02:46:38.779] iteration 83 : loss : 1.043000, loss_ce: 2.097285, loss_dice: 0.779429
[02:46:38.861] iteration 84 : loss : 1.162866, loss_ce: 2.334826, loss_dice: 0.869876
[02:46:38.940] iteration 85 : loss : 1.071667, loss_ce: 2.088356, loss_dice: 0.817494
[02:46:39.018] iteration 86 : loss : 1.074986, loss_ce: 2.084585, loss_dice: 0.822586
[02:46:39.096] iteration 87 : loss : 1.025853, loss_ce: 2.035080, loss_dice: 0.773546
[02:46:39.175] iteration 88 : loss : 1.169580, loss_ce: 2.364532, loss_dice: 0.870842
[02:46:39.254] iteration 89 : loss : 0.986445, loss_ce: 1.860415, loss_dice: 0.767953
[02:46:39.332] iteration 90 : loss : 0.991314, loss_ce: 1.882825, loss_dice: 0.768436
[02:46:39.410] iteration 91 : loss : 1.141659, loss_ce: 2.243272, loss_dice: 0.866255
[02:46:39.487] iteration 92 : loss : 1.126620, loss_ce: 2.180526, loss_dice: 0.863144
[02:46:39.565] iteration 93 : loss : 0.986409, loss_ce: 1.583896, loss_dice: 0.837037
[02:46:39.645] iteration 94 : loss : 1.024562, loss_ce: 2.013951, loss_dice: 0.777214
[02:46:39.726] iteration 95 : loss : 1.005444, loss_ce: 1.944342, loss_dice: 0.770719
[02:46:39.805] iteration 96 : loss : 1.072751, loss_ce: 2.049721, loss_dice: 0.828508
[02:46:39.885] iteration 97 : loss : 1.162668, loss_ce: 2.517477, loss_dice: 0.823966
[02:46:39.963] iteration 98 : loss : 1.012321, loss_ce: 2.063353, loss_dice: 0.749563
[02:46:40.044] iteration 99 : loss : 1.117713, loss_ce: 2.101318, loss_dice: 0.871812
[02:46:40.127] iteration 100 : loss : 1.063333, loss_ce: 1.993629, loss_dice: 0.830759
[02:46:40.217] iteration 101 : loss : 1.320349, loss_ce: 3.127498, loss_dice: 0.868562
[02:46:40.296] iteration 102 : loss : 1.019269, loss_ce: 1.874230, loss_dice: 0.805528
[02:46:40.377] iteration 103 : loss : 1.004824, loss_ce: 1.912410, loss_dice: 0.777928
[02:46:40.455] iteration 104 : loss : 1.043589, loss_ce: 1.929390, loss_dice: 0.822139
[02:46:40.535] iteration 105 : loss : 1.265572, loss_ce: 2.937536, loss_dice: 0.847581
[02:46:40.612] iteration 106 : loss : 1.305093, loss_ce: 2.999861, loss_dice: 0.881400
[02:46:40.692] iteration 107 : loss : 1.066968, loss_ce: 1.983405, loss_dice: 0.837859
[02:46:40.771] iteration 108 : loss : 1.126311, loss_ce: 2.146660, loss_dice: 0.871223
[02:46:40.850] iteration 109 : loss : 1.111218, loss_ce: 2.045024, loss_dice: 0.877767
[02:46:40.928] iteration 110 : loss : 1.073816, loss_ce: 1.879925, loss_dice: 0.872289
[02:46:41.009] iteration 111 : loss : 1.057914, loss_ce: 2.048875, loss_dice: 0.810174
[02:46:41.087] iteration 112 : loss : 1.181330, loss_ce: 2.563786, loss_dice: 0.835716
[02:46:41.166] iteration 113 : loss : 1.086347, loss_ce: 2.301676, loss_dice: 0.782515
[02:46:41.245] iteration 114 : loss : 1.127162, loss_ce: 2.083092, loss_dice: 0.888179
[02:46:41.325] iteration 115 : loss : 1.116783, loss_ce: 2.449185, loss_dice: 0.783682
[02:46:41.405] iteration 116 : loss : 1.154807, loss_ce: 2.261949, loss_dice: 0.878021
[02:46:41.485] iteration 117 : loss : 1.161008, loss_ce: 2.318986, loss_dice: 0.871513
[02:46:41.563] iteration 118 : loss : 1.115246, loss_ce: 2.264096, loss_dice: 0.828034
[02:46:41.643] iteration 119 : loss : 1.073735, loss_ce: 1.877945, loss_dice: 0.872683
[02:46:41.721] iteration 120 : loss : 1.165952, loss_ce: 2.344050, loss_dice: 0.871428
[02:46:41.811] iteration 121 : loss : 1.137672, loss_ce: 2.293998, loss_dice: 0.848591
[02:46:41.890] iteration 122 : loss : 1.150143, loss_ce: 2.418762, loss_dice: 0.832988
[02:46:41.970] iteration 123 : loss : 1.090529, loss_ce: 1.952331, loss_dice: 0.875079
[02:46:42.048] iteration 124 : loss : 1.066638, loss_ce: 2.031528, loss_dice: 0.825415
[02:46:42.127] iteration 125 : loss : 1.172446, loss_ce: 2.499704, loss_dice: 0.840631
[02:46:42.206] iteration 126 : loss : 1.022623, loss_ce: 1.810000, loss_dice: 0.825778
[02:46:42.285] iteration 127 : loss : 1.061960, loss_ce: 1.805897, loss_dice: 0.875975
[02:46:42.366] iteration 128 : loss : 1.193507, loss_ce: 2.663559, loss_dice: 0.825994
[02:46:42.450] iteration 129 : loss : 1.121257, loss_ce: 2.045472, loss_dice: 0.890203
[02:46:42.532] iteration 130 : loss : 1.080629, loss_ce: 1.896479, loss_dice: 0.876666
[02:46:42.613] iteration 131 : loss : 1.068731, loss_ce: 2.076435, loss_dice: 0.816804
[02:46:42.696] iteration 132 : loss : 1.113937, loss_ce: 2.030377, loss_dice: 0.884827
[02:46:42.776] iteration 133 : loss : 1.168282, loss_ce: 2.305506, loss_dice: 0.883976
[02:46:42.856] iteration 134 : loss : 1.108115, loss_ce: 2.054622, loss_dice: 0.871488
[02:46:42.936] iteration 135 : loss : 1.084891, loss_ce: 1.906065, loss_dice: 0.879598
[02:46:43.016] iteration 136 : loss : 1.042857, loss_ce: 1.760287, loss_dice: 0.863500
[02:46:43.095] iteration 137 : loss : 1.050858, loss_ce: 1.818251, loss_dice: 0.859010
[02:46:43.175] iteration 138 : loss : 1.090968, loss_ce: 2.103140, loss_dice: 0.837925
[02:46:43.257] iteration 139 : loss : 1.039713, loss_ce: 1.857257, loss_dice: 0.835327
[02:46:43.337] iteration 140 : loss : 1.119321, loss_ce: 2.280168, loss_dice: 0.829109
[02:46:43.427] iteration 141 : loss : 1.095045, loss_ce: 1.993004, loss_dice: 0.870556
[02:46:43.505] iteration 142 : loss : 1.196652, loss_ce: 2.476955, loss_dice: 0.876576
[02:46:43.588] iteration 143 : loss : 1.161586, loss_ce: 2.322534, loss_dice: 0.871349
[02:46:43.669] iteration 144 : loss : 1.144461, loss_ce: 2.282440, loss_dice: 0.859967
[02:46:43.751] iteration 145 : loss : 1.084041, loss_ce: 1.956474, loss_dice: 0.865932
[02:46:43.834] iteration 146 : loss : 1.070270, loss_ce: 1.939579, loss_dice: 0.852943
[02:46:43.916] iteration 147 : loss : 1.100656, loss_ce: 2.202772, loss_dice: 0.825127
[02:46:43.999] iteration 148 : loss : 1.000208, loss_ce: 1.439248, loss_dice: 0.890448
[02:46:44.080] iteration 149 : loss : 1.015437, loss_ce: 1.738946, loss_dice: 0.834559
[02:46:44.161] iteration 150 : loss : 1.209105, loss_ce: 2.550621, loss_dice: 0.873727
[02:46:44.244] iteration 151 : loss : 1.111880, loss_ce: 2.080079, loss_dice: 0.869830
[02:46:44.326] iteration 152 : loss : 1.133344, loss_ce: 2.182664, loss_dice: 0.871014
[02:46:44.409] iteration 153 : loss : 1.039914, loss_ce: 1.891440, loss_dice: 0.827033
[02:46:44.494] iteration 154 : loss : 0.966706, loss_ce: 1.541875, loss_dice: 0.822913
[02:46:44.575] iteration 155 : loss : 1.003079, loss_ce: 1.764128, loss_dice: 0.812817
[02:46:44.657] iteration 156 : loss : 1.053792, loss_ce: 1.936919, loss_dice: 0.833011
[02:46:44.744] iteration 157 : loss : 1.067119, loss_ce: 2.041644, loss_dice: 0.823488
[02:46:44.827] iteration 158 : loss : 1.082566, loss_ce: 2.102871, loss_dice: 0.827490
[02:46:44.912] iteration 159 : loss : 0.989018, loss_ce: 1.653208, loss_dice: 0.822970
[02:46:44.995] iteration 160 : loss : 1.086159, loss_ce: 1.972681, loss_dice: 0.864528
[02:46:45.090] iteration 161 : loss : 1.015294, loss_ce: 1.797063, loss_dice: 0.819852
[02:46:45.173] iteration 162 : loss : 1.071154, loss_ce: 1.891602, loss_dice: 0.866041
[02:46:45.256] iteration 163 : loss : 1.053511, loss_ce: 1.970966, loss_dice: 0.824147
[02:46:45.338] iteration 164 : loss : 1.085464, loss_ce: 1.991328, loss_dice: 0.858997
[02:46:45.423] iteration 165 : loss : 1.048555, loss_ce: 1.942792, loss_dice: 0.824996
[02:46:45.506] iteration 166 : loss : 1.068336, loss_ce: 1.913904, loss_dice: 0.856945
[02:46:45.588] iteration 167 : loss : 1.073427, loss_ce: 2.027950, loss_dice: 0.834796
[02:46:45.668] iteration 168 : loss : 1.086913, loss_ce: 2.085036, loss_dice: 0.837382
[02:46:45.747] iteration 169 : loss : 1.026184, loss_ce: 1.831228, loss_dice: 0.824923
[02:46:45.827] iteration 170 : loss : 1.157125, loss_ce: 2.474084, loss_dice: 0.827886
[02:46:45.905] iteration 171 : loss : 1.085562, loss_ce: 1.947479, loss_dice: 0.870082
[02:46:45.985] iteration 172 : loss : 1.140377, loss_ce: 2.237275, loss_dice: 0.866152
[02:46:46.065] iteration 173 : loss : 1.102206, loss_ce: 2.053137, loss_dice: 0.864473
[02:46:46.146] iteration 174 : loss : 1.045779, loss_ce: 1.946949, loss_dice: 0.820486
[02:46:46.226] iteration 175 : loss : 1.081527, loss_ce: 2.113665, loss_dice: 0.823492
[02:46:46.305] iteration 176 : loss : 1.099524, loss_ce: 2.000595, loss_dice: 0.874256
[02:46:46.385] iteration 177 : loss : 1.064172, loss_ce: 1.763006, loss_dice: 0.889463
[02:46:46.463] iteration 178 : loss : 1.065907, loss_ce: 2.092823, loss_dice: 0.809177
[02:46:46.544] iteration 179 : loss : 1.081286, loss_ce: 2.115945, loss_dice: 0.822622
[02:46:46.624] iteration 180 : loss : 1.125451, loss_ce: 2.183925, loss_dice: 0.860833
[02:46:46.713] iteration 181 : loss : 1.075992, loss_ce: 1.907754, loss_dice: 0.868052
[02:46:46.793] iteration 182 : loss : 1.033900, loss_ce: 1.860979, loss_dice: 0.827130
[02:46:46.873] iteration 183 : loss : 1.068000, loss_ce: 1.881068, loss_dice: 0.864733
[02:46:46.953] iteration 184 : loss : 1.168598, loss_ce: 2.511868, loss_dice: 0.832780
[02:46:47.035] iteration 185 : loss : 1.067521, loss_ce: 2.007990, loss_dice: 0.832404
[02:46:47.114] iteration 186 : loss : 0.993042, loss_ce: 1.913221, loss_dice: 0.762997
[02:46:47.195] iteration 187 : loss : 1.116121, loss_ce: 2.086186, loss_dice: 0.873605
[02:46:47.275] iteration 188 : loss : 1.035288, loss_ce: 1.884769, loss_dice: 0.822917
[02:46:47.354] iteration 189 : loss : 1.094446, loss_ce: 2.381100, loss_dice: 0.772783
[02:46:47.435] iteration 190 : loss : 1.087033, loss_ce: 2.137391, loss_dice: 0.824444
[02:46:47.515] iteration 191 : loss : 1.017260, loss_ce: 1.809453, loss_dice: 0.819212
[02:46:47.593] iteration 192 : loss : 1.076778, loss_ce: 2.127700, loss_dice: 0.814048
[02:46:47.674] iteration 193 : loss : 1.126193, loss_ce: 2.134933, loss_dice: 0.874008
[02:46:47.754] iteration 194 : loss : 1.047606, loss_ce: 1.961682, loss_dice: 0.819087
[02:46:47.834] iteration 195 : loss : 1.048138, loss_ce: 1.995236, loss_dice: 0.811363
[02:46:47.924] iteration 196 : loss : 1.134271, loss_ce: 2.291832, loss_dice: 0.844881
[02:46:48.004] iteration 197 : loss : 1.145104, loss_ce: 2.236814, loss_dice: 0.872177
[02:46:48.084] iteration 198 : loss : 1.134504, loss_ce: 2.406825, loss_dice: 0.816423
[02:46:48.163] iteration 199 : loss : 1.117153, loss_ce: 2.132054, loss_dice: 0.863428
[02:46:48.244] iteration 200 : loss : 1.000256, loss_ce: 1.556084, loss_dice: 0.861299
[02:46:48.333] iteration 201 : loss : 1.090918, loss_ce: 1.979398, loss_dice: 0.868798
[02:46:48.412] iteration 202 : loss : 1.026284, loss_ce: 1.585599, loss_dice: 0.886456
[02:46:48.493] iteration 203 : loss : 1.169088, loss_ce: 2.326972, loss_dice: 0.879616
[02:46:48.573] iteration 204 : loss : 1.175639, loss_ce: 2.376607, loss_dice: 0.875396
[02:46:48.653] iteration 205 : loss : 1.061791, loss_ce: 1.845058, loss_dice: 0.865974
[02:46:48.733] iteration 206 : loss : 1.083758, loss_ce: 1.958519, loss_dice: 0.865068
[02:46:48.812] iteration 207 : loss : 1.004993, loss_ce: 1.579685, loss_dice: 0.861320
