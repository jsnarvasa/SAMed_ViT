[02:45:47.151] Namespace(AdamW=True, base_lr=0.005, batch_size=3, ckpt='checkpoints/sam_vit_b_01ec64.pth', dataset='Synapse', deterministic=1, dice_param=0.8, exp='Synapse_128', img_size=128, is_pretrain=True, list_dir='./lists/lists_PASTIS', lora_ckpt=None, max_epochs=200, max_iterations=30000, module='sam_lora_image_encoder', n_gpu=1, num_classes=20, num_workers=0, output='/home/narvjes/repos/SAMed-jnar/output', rank=4, root_path='/home/narvjes/data/PASTIS/SAMed', seed=1234, stop_epoch=200, vit_name='vit_b', warmup=True, warmup_period=250)
[02:45:47.156] 811 iterations per epoch. 162200 max iterations 
[02:45:47.286] iteration 1 : loss : 1.470964, loss_ce: 3.533817, loss_dice: 0.955251
[02:45:47.370] iteration 2 : loss : 1.407619, loss_ce: 3.262938, loss_dice: 0.943789
[02:45:47.446] iteration 3 : loss : 1.339890, loss_ce: 2.942857, loss_dice: 0.939148
[02:45:47.522] iteration 4 : loss : 1.298752, loss_ce: 2.661355, loss_dice: 0.958101
[02:45:47.600] iteration 5 : loss : 1.264419, loss_ce: 2.509187, loss_dice: 0.953227
[02:45:47.678] iteration 6 : loss : 1.190835, loss_ce: 2.122622, loss_dice: 0.957888
[02:45:47.755] iteration 7 : loss : 1.367036, loss_ce: 3.027908, loss_dice: 0.951818
[02:45:47.832] iteration 8 : loss : 1.219941, loss_ce: 2.299681, loss_dice: 0.950006
[02:45:47.909] iteration 9 : loss : 1.172304, loss_ce: 2.143796, loss_dice: 0.929431
[02:45:47.986] iteration 10 : loss : 1.210294, loss_ce: 2.282751, loss_dice: 0.942179
[02:45:48.061] iteration 11 : loss : 1.229589, loss_ce: 2.412427, loss_dice: 0.933880
[02:45:48.138] iteration 12 : loss : 1.245771, loss_ce: 2.468769, loss_dice: 0.940021
[02:45:48.214] iteration 13 : loss : 1.212534, loss_ce: 2.325110, loss_dice: 0.934390
[02:45:48.292] iteration 14 : loss : 1.187614, loss_ce: 2.228016, loss_dice: 0.927514
[02:45:48.369] iteration 15 : loss : 1.118981, loss_ce: 1.858504, loss_dice: 0.934101
[02:45:48.446] iteration 16 : loss : 1.184908, loss_ce: 2.192173, loss_dice: 0.933092
[02:45:48.523] iteration 17 : loss : 1.097102, loss_ce: 1.771447, loss_dice: 0.928516
[02:45:48.603] iteration 18 : loss : 1.131681, loss_ce: 1.909234, loss_dice: 0.937293
[02:45:48.680] iteration 19 : loss : 1.134360, loss_ce: 1.939305, loss_dice: 0.933124
[02:45:48.758] iteration 20 : loss : 1.097593, loss_ce: 1.734457, loss_dice: 0.938377
[02:45:48.849] iteration 21 : loss : 1.121063, loss_ce: 1.876683, loss_dice: 0.932158
[02:45:48.925] iteration 22 : loss : 1.086938, loss_ce: 1.707607, loss_dice: 0.931771
[02:45:49.001] iteration 23 : loss : 1.191075, loss_ce: 2.227683, loss_dice: 0.931923
[02:45:49.077] iteration 24 : loss : 1.169923, loss_ce: 2.102301, loss_dice: 0.936828
[02:45:49.157] iteration 25 : loss : 1.141353, loss_ce: 1.982462, loss_dice: 0.931076
[02:45:49.241] iteration 26 : loss : 1.194302, loss_ce: 2.245080, loss_dice: 0.931607
[02:45:49.324] iteration 27 : loss : 1.211577, loss_ce: 2.309591, loss_dice: 0.937074
[02:45:49.405] iteration 28 : loss : 1.161864, loss_ce: 2.102769, loss_dice: 0.926638
[02:45:49.485] iteration 29 : loss : 1.231732, loss_ce: 2.449954, loss_dice: 0.927177
[02:45:49.564] iteration 30 : loss : 1.175336, loss_ce: 2.176399, loss_dice: 0.925070
[02:45:49.648] iteration 31 : loss : 1.178504, loss_ce: 2.185493, loss_dice: 0.926757
[02:45:49.729] iteration 32 : loss : 1.203187, loss_ce: 2.304184, loss_dice: 0.927938
[02:45:49.809] iteration 33 : loss : 1.079210, loss_ce: 1.699761, loss_dice: 0.924073
[02:45:49.889] iteration 34 : loss : 1.159338, loss_ce: 2.194246, loss_dice: 0.900611
[02:45:49.967] iteration 35 : loss : 1.106101, loss_ce: 2.132302, loss_dice: 0.849551
[02:45:50.050] iteration 36 : loss : 1.020927, loss_ce: 1.774928, loss_dice: 0.832427
[02:45:50.138] iteration 37 : loss : 0.923406, loss_ce: 1.330310, loss_dice: 0.821680
[02:45:50.238] iteration 38 : loss : 1.146788, loss_ce: 2.692084, loss_dice: 0.760464
[02:45:50.333] iteration 39 : loss : 0.913642, loss_ce: 1.792958, loss_dice: 0.693813
[02:45:50.409] iteration 40 : loss : 1.400615, loss_ce: 3.824888, loss_dice: 0.794546
[02:45:50.496] iteration 41 : loss : 1.288395, loss_ce: 3.066792, loss_dice: 0.843796
[02:45:50.575] iteration 42 : loss : 1.155411, loss_ce: 2.463290, loss_dice: 0.828441
[02:45:50.654] iteration 43 : loss : 1.114849, loss_ce: 2.465429, loss_dice: 0.777204
[02:45:50.732] iteration 44 : loss : 0.937970, loss_ce: 1.688059, loss_dice: 0.750448
[02:45:50.808] iteration 45 : loss : 1.158924, loss_ce: 2.602915, loss_dice: 0.797926
[02:45:50.885] iteration 46 : loss : 1.395163, loss_ce: 3.552452, loss_dice: 0.855841
[02:45:50.968] iteration 47 : loss : 1.050079, loss_ce: 2.233992, loss_dice: 0.754101
[02:45:51.045] iteration 48 : loss : 1.204864, loss_ce: 2.836558, loss_dice: 0.796940
[02:45:51.123] iteration 49 : loss : 0.943231, loss_ce: 1.507686, loss_dice: 0.802117
[02:45:51.201] iteration 50 : loss : 1.112568, loss_ce: 2.326065, loss_dice: 0.809194
[02:45:51.280] iteration 51 : loss : 1.188091, loss_ce: 2.722055, loss_dice: 0.804600
[02:45:51.358] iteration 52 : loss : 1.033430, loss_ce: 2.014126, loss_dice: 0.788256
[02:45:51.435] iteration 53 : loss : 1.258754, loss_ce: 3.112491, loss_dice: 0.795320
[02:45:51.513] iteration 54 : loss : 1.092602, loss_ce: 2.261851, loss_dice: 0.800290
[02:45:51.590] iteration 55 : loss : 1.106515, loss_ce: 2.389387, loss_dice: 0.785797
[02:45:51.667] iteration 56 : loss : 1.086932, loss_ce: 2.499478, loss_dice: 0.733796
[02:45:51.743] iteration 57 : loss : 1.037756, loss_ce: 2.018633, loss_dice: 0.792537
[02:45:51.818] iteration 58 : loss : 1.219413, loss_ce: 2.945965, loss_dice: 0.787775
[02:45:51.894] iteration 59 : loss : 0.895678, loss_ce: 1.490965, loss_dice: 0.746856
[02:45:51.975] iteration 60 : loss : 1.026642, loss_ce: 2.172165, loss_dice: 0.740262
[02:45:52.063] iteration 61 : loss : 1.230099, loss_ce: 2.747952, loss_dice: 0.850636
[02:45:52.141] iteration 62 : loss : 1.234334, loss_ce: 2.830158, loss_dice: 0.835377
[02:45:52.218] iteration 63 : loss : 1.095300, loss_ce: 2.513886, loss_dice: 0.740654
[02:45:52.297] iteration 64 : loss : 0.993197, loss_ce: 1.843008, loss_dice: 0.780744
[02:45:52.377] iteration 65 : loss : 1.074625, loss_ce: 2.045070, loss_dice: 0.832014
[02:45:52.459] iteration 66 : loss : 1.105389, loss_ce: 2.400803, loss_dice: 0.781535
[02:45:52.539] iteration 67 : loss : 1.043053, loss_ce: 2.111602, loss_dice: 0.775916
[02:45:52.616] iteration 68 : loss : 1.256582, loss_ce: 2.947255, loss_dice: 0.833913
[02:45:52.695] iteration 69 : loss : 1.167525, loss_ce: 2.303415, loss_dice: 0.883552
[02:45:52.771] iteration 70 : loss : 1.019796, loss_ce: 1.897019, loss_dice: 0.800490
[02:45:52.848] iteration 71 : loss : 1.217453, loss_ce: 2.728959, loss_dice: 0.839576
[02:45:52.925] iteration 72 : loss : 0.949928, loss_ce: 1.573954, loss_dice: 0.793922
[02:45:53.003] iteration 73 : loss : 0.946210, loss_ce: 1.787133, loss_dice: 0.735979
[02:45:53.083] iteration 74 : loss : 1.031121, loss_ce: 2.000123, loss_dice: 0.788871
[02:45:53.162] iteration 75 : loss : 1.098931, loss_ce: 2.331666, loss_dice: 0.790747
[02:45:53.240] iteration 76 : loss : 1.154990, loss_ce: 2.425366, loss_dice: 0.837396
[02:45:53.320] iteration 77 : loss : 1.002976, loss_ce: 1.864182, loss_dice: 0.787675
[02:45:53.398] iteration 78 : loss : 1.021593, loss_ce: 1.966740, loss_dice: 0.785307
[02:45:53.480] iteration 79 : loss : 0.945244, loss_ce: 1.606277, loss_dice: 0.779986
[02:45:53.559] iteration 80 : loss : 0.969056, loss_ce: 1.898543, loss_dice: 0.736684
[02:45:53.649] iteration 81 : loss : 1.041702, loss_ce: 1.870266, loss_dice: 0.834561
[02:45:53.729] iteration 82 : loss : 1.021639, loss_ce: 2.121140, loss_dice: 0.746764
[02:45:53.806] iteration 83 : loss : 1.089691, loss_ce: 2.117439, loss_dice: 0.832754
[02:45:53.881] iteration 84 : loss : 1.111294, loss_ce: 2.223050, loss_dice: 0.833355
[02:45:53.958] iteration 85 : loss : 1.000138, loss_ce: 1.863236, loss_dice: 0.784363
[02:45:54.034] iteration 86 : loss : 1.044327, loss_ce: 2.252128, loss_dice: 0.742377
[02:45:54.111] iteration 87 : loss : 0.958365, loss_ce: 1.645242, loss_dice: 0.786645
[02:45:54.190] iteration 88 : loss : 0.981536, loss_ce: 1.942792, loss_dice: 0.741221
[02:45:54.267] iteration 89 : loss : 1.137070, loss_ce: 2.298371, loss_dice: 0.846744
[02:45:54.346] iteration 90 : loss : 0.947619, loss_ce: 1.591459, loss_dice: 0.786658
[02:45:54.425] iteration 91 : loss : 1.040571, loss_ce: 2.248907, loss_dice: 0.738487
[02:45:54.504] iteration 92 : loss : 1.101465, loss_ce: 2.517022, loss_dice: 0.747576
[02:45:54.580] iteration 93 : loss : 1.085928, loss_ce: 2.467336, loss_dice: 0.740576
[02:45:54.660] iteration 94 : loss : 1.055071, loss_ce: 2.144713, loss_dice: 0.782661
[02:45:54.737] iteration 95 : loss : 1.077340, loss_ce: 2.056499, loss_dice: 0.832550
[02:45:54.815] iteration 96 : loss : 1.165748, loss_ce: 2.295305, loss_dice: 0.883359
[02:45:54.893] iteration 97 : loss : 1.062610, loss_ce: 2.086327, loss_dice: 0.806680
[02:45:54.973] iteration 98 : loss : 1.208458, loss_ce: 2.678109, loss_dice: 0.841045
[02:45:55.051] iteration 99 : loss : 0.983866, loss_ce: 1.776136, loss_dice: 0.785799
[02:45:55.131] iteration 100 : loss : 0.970458, loss_ce: 1.594396, loss_dice: 0.814473
[02:45:55.222] iteration 101 : loss : 1.022867, loss_ce: 1.919108, loss_dice: 0.798806
[02:45:55.300] iteration 102 : loss : 1.245590, loss_ce: 2.645295, loss_dice: 0.895664
[02:45:55.378] iteration 103 : loss : 0.989817, loss_ce: 1.961866, loss_dice: 0.746804
[02:45:55.454] iteration 104 : loss : 0.966836, loss_ce: 1.501017, loss_dice: 0.833291
[02:45:55.529] iteration 105 : loss : 1.059391, loss_ce: 2.364632, loss_dice: 0.733080
[02:45:55.605] iteration 106 : loss : 1.141239, loss_ce: 2.365530, loss_dice: 0.835166
[02:45:55.684] iteration 107 : loss : 1.048386, loss_ce: 2.115066, loss_dice: 0.781716
[02:45:55.761] iteration 108 : loss : 0.985247, loss_ce: 1.627013, loss_dice: 0.824805
[02:45:55.839] iteration 109 : loss : 1.128477, loss_ce: 2.249642, loss_dice: 0.848185
[02:45:55.915] iteration 110 : loss : 1.069761, loss_ce: 2.343833, loss_dice: 0.751242
[02:45:55.991] iteration 111 : loss : 1.149236, loss_ce: 2.332789, loss_dice: 0.853348
[02:45:56.069] iteration 112 : loss : 1.090177, loss_ce: 2.466130, loss_dice: 0.746188
[02:45:56.145] iteration 113 : loss : 1.085557, loss_ce: 2.284627, loss_dice: 0.785789
[02:45:56.222] iteration 114 : loss : 1.145121, loss_ce: 2.241921, loss_dice: 0.870921
[02:45:56.299] iteration 115 : loss : 1.069539, loss_ce: 2.226171, loss_dice: 0.780382
[02:45:56.375] iteration 116 : loss : 1.015582, loss_ce: 2.135029, loss_dice: 0.735720
[02:45:56.452] iteration 117 : loss : 1.130021, loss_ce: 2.550803, loss_dice: 0.774825
[02:45:56.527] iteration 118 : loss : 1.141451, loss_ce: 2.386094, loss_dice: 0.830290
[02:45:56.605] iteration 119 : loss : 0.993533, loss_ce: 2.049139, loss_dice: 0.729631
[02:45:56.680] iteration 120 : loss : 0.991804, loss_ce: 2.015663, loss_dice: 0.735840
[02:45:56.767] iteration 121 : loss : 1.152502, loss_ce: 2.402000, loss_dice: 0.840128
[02:45:56.842] iteration 122 : loss : 1.097401, loss_ce: 2.516042, loss_dice: 0.742741
[02:45:56.917] iteration 123 : loss : 1.142285, loss_ce: 2.183021, loss_dice: 0.882101
[02:45:56.992] iteration 124 : loss : 1.041740, loss_ce: 1.812975, loss_dice: 0.848932
[02:45:57.068] iteration 125 : loss : 1.054248, loss_ce: 2.133829, loss_dice: 0.784353
[02:45:57.145] iteration 126 : loss : 1.107512, loss_ce: 2.360156, loss_dice: 0.794350
[02:45:57.223] iteration 127 : loss : 1.028414, loss_ce: 1.970582, loss_dice: 0.792872
[02:45:57.300] iteration 128 : loss : 1.138973, loss_ce: 2.330938, loss_dice: 0.840982
[02:45:57.378] iteration 129 : loss : 1.162711, loss_ce: 2.489488, loss_dice: 0.831017
[02:45:57.457] iteration 130 : loss : 1.145964, loss_ce: 2.566063, loss_dice: 0.790939
[02:45:57.533] iteration 131 : loss : 1.126638, loss_ce: 2.470614, loss_dice: 0.790644
[02:45:57.610] iteration 132 : loss : 1.158337, loss_ce: 2.237157, loss_dice: 0.888633
[02:45:57.688] iteration 133 : loss : 1.148318, loss_ce: 2.371336, loss_dice: 0.842564
[02:45:57.765] iteration 134 : loss : 1.091629, loss_ce: 2.142215, loss_dice: 0.828983
[02:45:57.842] iteration 135 : loss : 1.019023, loss_ce: 1.965324, loss_dice: 0.782447
[02:45:57.919] iteration 136 : loss : 0.986763, loss_ce: 1.777990, loss_dice: 0.788956
[02:45:57.996] iteration 137 : loss : 1.095528, loss_ce: 2.263552, loss_dice: 0.803522
[02:45:58.072] iteration 138 : loss : 1.068418, loss_ce: 1.987678, loss_dice: 0.838603
[02:45:58.148] iteration 139 : loss : 0.983409, loss_ce: 1.772047, loss_dice: 0.786249
[02:45:58.224] iteration 140 : loss : 1.276821, loss_ce: 2.979550, loss_dice: 0.851139
[02:45:58.312] iteration 141 : loss : 1.146056, loss_ce: 2.265011, loss_dice: 0.866317
[02:45:58.388] iteration 142 : loss : 1.134355, loss_ce: 2.341562, loss_dice: 0.832553
[02:45:58.465] iteration 143 : loss : 1.119591, loss_ce: 2.244252, loss_dice: 0.838426
[02:45:58.540] iteration 144 : loss : 1.127305, loss_ce: 2.142684, loss_dice: 0.873461
[02:45:58.616] iteration 145 : loss : 1.095912, loss_ce: 1.950583, loss_dice: 0.882245
[02:45:58.692] iteration 146 : loss : 0.948691, loss_ce: 1.432589, loss_dice: 0.827716
[02:45:58.768] iteration 147 : loss : 1.091621, loss_ce: 2.138355, loss_dice: 0.829937
[02:45:58.844] iteration 148 : loss : 0.965923, loss_ce: 1.580300, loss_dice: 0.812329
[02:45:58.919] iteration 149 : loss : 1.163170, loss_ce: 2.497544, loss_dice: 0.829576
[02:45:58.994] iteration 150 : loss : 1.027552, loss_ce: 1.952914, loss_dice: 0.796212
[02:45:59.069] iteration 151 : loss : 1.064936, loss_ce: 2.176425, loss_dice: 0.787064
[02:45:59.146] iteration 152 : loss : 1.096042, loss_ce: 1.973347, loss_dice: 0.876716
[02:45:59.223] iteration 153 : loss : 1.132446, loss_ce: 2.556160, loss_dice: 0.776518
[02:45:59.306] iteration 154 : loss : 1.066841, loss_ce: 2.199107, loss_dice: 0.783775
[02:45:59.392] iteration 155 : loss : 1.177873, loss_ce: 2.398985, loss_dice: 0.872595
[02:45:59.478] iteration 156 : loss : 1.067815, loss_ce: 2.061505, loss_dice: 0.819393
[02:45:59.562] iteration 157 : loss : 1.105402, loss_ce: 2.257477, loss_dice: 0.817384
[02:45:59.644] iteration 158 : loss : 1.106871, loss_ce: 2.233813, loss_dice: 0.825136
[02:45:59.723] iteration 159 : loss : 0.969661, loss_ce: 1.911933, loss_dice: 0.734093
[02:45:59.800] iteration 160 : loss : 1.089062, loss_ce: 2.339941, loss_dice: 0.776343
[02:45:59.887] iteration 161 : loss : 1.325725, loss_ce: 3.441377, loss_dice: 0.796812
[02:45:59.963] iteration 162 : loss : 1.069775, loss_ce: 2.342925, loss_dice: 0.751487
[02:46:00.038] iteration 163 : loss : 1.049179, loss_ce: 2.221104, loss_dice: 0.756198
[02:46:00.115] iteration 164 : loss : 1.006221, loss_ce: 2.105089, loss_dice: 0.731505
[02:46:00.192] iteration 165 : loss : 1.086933, loss_ce: 2.309825, loss_dice: 0.781209
[02:46:00.267] iteration 166 : loss : 0.998191, loss_ce: 2.175800, loss_dice: 0.703789
[02:46:00.345] iteration 167 : loss : 1.057402, loss_ce: 2.128940, loss_dice: 0.789518
[02:46:00.422] iteration 168 : loss : 1.109670, loss_ce: 2.415655, loss_dice: 0.783174
[02:46:00.498] iteration 169 : loss : 0.980286, loss_ce: 1.800472, loss_dice: 0.775240
[02:46:00.573] iteration 170 : loss : 1.224154, loss_ce: 2.911328, loss_dice: 0.802361
[02:46:00.649] iteration 171 : loss : 1.128050, loss_ce: 2.470435, loss_dice: 0.792453
[02:46:00.727] iteration 172 : loss : 1.009178, loss_ce: 1.694045, loss_dice: 0.837961
[02:46:00.802] iteration 173 : loss : 1.004430, loss_ce: 1.815275, loss_dice: 0.801718
[02:46:00.879] iteration 174 : loss : 1.073526, loss_ce: 2.220359, loss_dice: 0.786818
[02:46:00.955] iteration 175 : loss : 1.025329, loss_ce: 2.201760, loss_dice: 0.731221
[02:46:01.034] iteration 176 : loss : 1.025564, loss_ce: 1.998363, loss_dice: 0.782364
[02:46:01.110] iteration 177 : loss : 1.102368, loss_ce: 2.116199, loss_dice: 0.848910
[02:46:01.189] iteration 178 : loss : 1.151002, loss_ce: 2.278192, loss_dice: 0.869204
[02:46:01.267] iteration 179 : loss : 0.962965, loss_ce: 1.686206, loss_dice: 0.782154
[02:46:01.346] iteration 180 : loss : 1.186670, loss_ce: 2.593157, loss_dice: 0.835049
[02:46:01.440] iteration 181 : loss : 1.158825, loss_ce: 2.358556, loss_dice: 0.858892
[02:46:01.521] iteration 182 : loss : 0.944296, loss_ce: 1.705835, loss_dice: 0.753911
[02:46:01.601] iteration 183 : loss : 0.944602, loss_ce: 1.795401, loss_dice: 0.731902
[02:46:01.680] iteration 184 : loss : 1.069030, loss_ce: 2.351530, loss_dice: 0.748405
[02:46:01.756] iteration 185 : loss : 1.141195, loss_ce: 2.362805, loss_dice: 0.835793
[02:46:01.833] iteration 186 : loss : 1.076025, loss_ce: 2.263367, loss_dice: 0.779190
[02:46:01.908] iteration 187 : loss : 1.086379, loss_ce: 2.111637, loss_dice: 0.830064
[02:46:01.993] iteration 188 : loss : 1.177338, loss_ce: 2.387021, loss_dice: 0.874918
[02:46:02.073] iteration 189 : loss : 1.252218, loss_ce: 2.954860, loss_dice: 0.826558
[02:46:02.154] iteration 190 : loss : 1.092806, loss_ce: 2.058357, loss_dice: 0.851419
[02:46:02.232] iteration 191 : loss : 0.997721, loss_ce: 2.038783, loss_dice: 0.737455
[02:46:02.308] iteration 192 : loss : 1.304333, loss_ce: 3.103688, loss_dice: 0.854494
[02:46:02.389] iteration 193 : loss : 1.043145, loss_ce: 2.087849, loss_dice: 0.781969
[02:46:02.468] iteration 194 : loss : 1.122620, loss_ce: 2.127455, loss_dice: 0.871411
[02:46:02.553] iteration 195 : loss : 1.132282, loss_ce: 2.149115, loss_dice: 0.878073
[02:46:02.633] iteration 196 : loss : 1.144676, loss_ce: 2.399800, loss_dice: 0.830895
[02:46:02.709] iteration 197 : loss : 0.977342, loss_ce: 1.536924, loss_dice: 0.837446
[02:46:02.784] iteration 198 : loss : 1.070643, loss_ce: 1.852979, loss_dice: 0.875059
[02:46:02.859] iteration 199 : loss : 1.025871, loss_ce: 2.018925, loss_dice: 0.777607
[02:46:02.936] iteration 200 : loss : 1.178248, loss_ce: 2.570658, loss_dice: 0.830146
[02:46:03.023] iteration 201 : loss : 1.169219, loss_ce: 2.485517, loss_dice: 0.840144
[02:46:03.099] iteration 202 : loss : 1.090917, loss_ce: 2.113935, loss_dice: 0.835162
[02:46:03.176] iteration 203 : loss : 1.030378, loss_ce: 1.852922, loss_dice: 0.824742
[02:46:03.252] iteration 204 : loss : 1.123227, loss_ce: 2.101215, loss_dice: 0.878730
[02:46:03.336] iteration 205 : loss : 0.896135, loss_ce: 1.133903, loss_dice: 0.836693
[02:46:03.414] iteration 206 : loss : 1.006754, loss_ce: 1.931986, loss_dice: 0.775446
[02:46:03.491] iteration 207 : loss : 1.064420, loss_ce: 2.188515, loss_dice: 0.783396
[02:46:03.566] iteration 208 : loss : 1.066099, loss_ce: 2.024110, loss_dice: 0.826597
[02:46:03.643] iteration 209 : loss : 1.057880, loss_ce: 2.168461, loss_dice: 0.780235
[02:46:03.718] iteration 210 : loss : 1.196304, loss_ce: 2.689173, loss_dice: 0.823087
[02:46:03.793] iteration 211 : loss : 1.101169, loss_ce: 2.152701, loss_dice: 0.838286
[02:46:03.868] iteration 212 : loss : 0.961100, loss_ce: 1.670403, loss_dice: 0.783774
