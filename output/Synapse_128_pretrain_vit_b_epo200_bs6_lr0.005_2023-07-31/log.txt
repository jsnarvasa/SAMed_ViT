[02:47:08.982] Namespace(AdamW=True, base_lr=0.005, batch_size=6, ckpt='checkpoints/sam_vit_b_01ec64.pth', dataset='Synapse', deterministic=1, dice_param=0.8, exp='Synapse_128', img_size=128, is_pretrain=True, list_dir='./lists/lists_PASTIS', lora_ckpt=None, max_epochs=200, max_iterations=30000, module='sam_lora_image_encoder', n_gpu=1, num_classes=20, num_workers=0, output='/home/narvjes/repos/SAMed-jnar/output', rank=4, root_path='/home/narvjes/data/PASTIS/SAMed', seed=1234, stop_epoch=200, vit_name='vit_b', warmup=True, warmup_period=250)
[02:47:08.987] 406 iterations per epoch. 81200 max iterations 
[02:47:09.129] iteration 1 : loss : 1.465543, loss_ce: 3.550925, loss_dice: 0.944198
[02:47:09.229] iteration 2 : loss : 1.363455, loss_ce: 3.038693, loss_dice: 0.944645
[02:47:09.321] iteration 3 : loss : 1.377217, loss_ce: 3.059498, loss_dice: 0.956647
[02:47:09.404] iteration 4 : loss : 1.298359, loss_ce: 2.746732, loss_dice: 0.936266
[02:47:09.488] iteration 5 : loss : 1.210821, loss_ce: 2.343660, loss_dice: 0.927611
[02:47:09.570] iteration 6 : loss : 1.274644, loss_ce: 2.633683, loss_dice: 0.934885
[02:47:09.657] iteration 7 : loss : 1.304172, loss_ce: 2.759356, loss_dice: 0.940376
[02:47:09.741] iteration 8 : loss : 1.183288, loss_ce: 2.195310, loss_dice: 0.930282
[02:47:09.829] iteration 9 : loss : 1.166242, loss_ce: 2.112755, loss_dice: 0.929614
[02:47:09.912] iteration 10 : loss : 1.170338, loss_ce: 2.096336, loss_dice: 0.938839
[02:47:09.995] iteration 11 : loss : 1.100731, loss_ce: 1.789319, loss_dice: 0.928584
[02:47:10.076] iteration 12 : loss : 1.217200, loss_ce: 2.341969, loss_dice: 0.936007
[02:47:10.161] iteration 13 : loss : 1.185126, loss_ce: 2.178775, loss_dice: 0.936713
[02:47:10.244] iteration 14 : loss : 1.188388, loss_ce: 2.251999, loss_dice: 0.922485
[02:47:10.331] iteration 15 : loss : 1.227230, loss_ce: 2.422163, loss_dice: 0.928496
[02:47:10.423] iteration 16 : loss : 1.221668, loss_ce: 2.415066, loss_dice: 0.923319
[02:47:10.511] iteration 17 : loss : 1.151816, loss_ce: 2.065614, loss_dice: 0.923366
[02:47:10.596] iteration 18 : loss : 1.126015, loss_ce: 1.946822, loss_dice: 0.920813
[02:47:10.681] iteration 19 : loss : 1.116235, loss_ce: 1.847660, loss_dice: 0.933378
[02:47:10.763] iteration 20 : loss : 1.170058, loss_ce: 2.132311, loss_dice: 0.929494
[02:47:10.857] iteration 21 : loss : 1.128037, loss_ce: 1.908427, loss_dice: 0.932940
[02:47:10.940] iteration 22 : loss : 1.106202, loss_ce: 1.817472, loss_dice: 0.928384
[02:47:11.019] iteration 23 : loss : 1.187609, loss_ce: 2.216669, loss_dice: 0.930344
[02:47:11.099] iteration 24 : loss : 1.163294, loss_ce: 2.110465, loss_dice: 0.926501
[02:47:11.182] iteration 25 : loss : 1.107252, loss_ce: 1.833154, loss_dice: 0.925776
[02:47:11.264] iteration 26 : loss : 1.158281, loss_ce: 2.074564, loss_dice: 0.929211
[02:47:11.347] iteration 27 : loss : 1.184233, loss_ce: 2.214813, loss_dice: 0.926588
[02:47:11.430] iteration 28 : loss : 1.244601, loss_ce: 2.492827, loss_dice: 0.932544
[02:47:11.510] iteration 29 : loss : 1.122555, loss_ce: 1.916764, loss_dice: 0.924003
[02:47:11.591] iteration 30 : loss : 1.108063, loss_ce: 1.846164, loss_dice: 0.923538
[02:47:11.674] iteration 31 : loss : 1.182201, loss_ce: 2.200346, loss_dice: 0.927665
[02:47:11.756] iteration 32 : loss : 1.130089, loss_ce: 1.948198, loss_dice: 0.925562
[02:47:11.838] iteration 33 : loss : 1.122598, loss_ce: 1.946282, loss_dice: 0.916677
[02:47:11.921] iteration 34 : loss : 1.169749, loss_ce: 2.232080, loss_dice: 0.904167
[02:47:12.003] iteration 35 : loss : 1.082965, loss_ce: 1.903018, loss_dice: 0.877952
[02:47:12.087] iteration 36 : loss : 1.108794, loss_ce: 2.043901, loss_dice: 0.875017
[02:47:12.171] iteration 37 : loss : 1.089401, loss_ce: 1.935133, loss_dice: 0.877967
[02:47:12.252] iteration 38 : loss : 1.155999, loss_ce: 2.264166, loss_dice: 0.878957
[02:47:12.335] iteration 39 : loss : 1.066104, loss_ce: 1.823189, loss_dice: 0.876833
[02:47:12.431] iteration 40 : loss : 1.058176, loss_ce: 1.786453, loss_dice: 0.876107
[02:47:12.522] iteration 41 : loss : 1.085728, loss_ce: 1.923271, loss_dice: 0.876343
[02:47:12.603] iteration 42 : loss : 1.097906, loss_ce: 1.978575, loss_dice: 0.877739
[02:47:12.685] iteration 43 : loss : 1.098510, loss_ce: 1.986581, loss_dice: 0.876492
[02:47:12.770] iteration 44 : loss : 1.069930, loss_ce: 1.857296, loss_dice: 0.873088
[02:47:12.852] iteration 45 : loss : 1.095182, loss_ce: 1.952454, loss_dice: 0.880864
[02:47:12.933] iteration 46 : loss : 1.130174, loss_ce: 2.183167, loss_dice: 0.866926
[02:47:13.014] iteration 47 : loss : 1.122566, loss_ce: 2.233894, loss_dice: 0.844734
[02:47:13.094] iteration 48 : loss : 1.104245, loss_ce: 2.020504, loss_dice: 0.875180
[02:47:13.176] iteration 49 : loss : 1.151837, loss_ce: 2.269504, loss_dice: 0.872421
[02:47:13.255] iteration 50 : loss : 1.040428, loss_ce: 1.691774, loss_dice: 0.877592
[02:47:13.335] iteration 51 : loss : 1.109556, loss_ce: 2.030433, loss_dice: 0.879337
[02:47:13.417] iteration 52 : loss : 1.018867, loss_ce: 1.568945, loss_dice: 0.881347
[02:47:13.499] iteration 53 : loss : 1.148580, loss_ce: 2.405953, loss_dice: 0.834237
[02:47:13.581] iteration 54 : loss : 1.063734, loss_ce: 2.015697, loss_dice: 0.825744
[02:47:13.663] iteration 55 : loss : 1.123463, loss_ce: 2.115726, loss_dice: 0.875397
[02:47:13.747] iteration 56 : loss : 1.127405, loss_ce: 2.159697, loss_dice: 0.869332
[02:47:13.829] iteration 57 : loss : 1.125407, loss_ce: 2.140193, loss_dice: 0.871710
[02:47:13.910] iteration 58 : loss : 1.108119, loss_ce: 2.214997, loss_dice: 0.831399
[02:47:13.992] iteration 59 : loss : 1.148155, loss_ce: 2.260632, loss_dice: 0.870036
[02:47:14.074] iteration 60 : loss : 1.101269, loss_ce: 2.202070, loss_dice: 0.826068
[02:47:14.164] iteration 61 : loss : 1.152523, loss_ce: 2.293224, loss_dice: 0.867347
[02:47:14.244] iteration 62 : loss : 1.033751, loss_ce: 1.669412, loss_dice: 0.874836
[02:47:14.324] iteration 63 : loss : 1.122884, loss_ce: 2.272173, loss_dice: 0.835562
[02:47:14.406] iteration 64 : loss : 1.111519, loss_ce: 2.040389, loss_dice: 0.879301
[02:47:14.488] iteration 65 : loss : 1.159415, loss_ce: 2.351143, loss_dice: 0.861483
[02:47:14.569] iteration 66 : loss : 1.142673, loss_ce: 2.232997, loss_dice: 0.870092
[02:47:14.652] iteration 67 : loss : 1.111116, loss_ce: 2.056265, loss_dice: 0.874829
[02:47:14.735] iteration 68 : loss : 1.204472, loss_ce: 2.382911, loss_dice: 0.909862
[02:47:14.816] iteration 69 : loss : 1.106748, loss_ce: 2.042790, loss_dice: 0.872737
[02:47:14.897] iteration 70 : loss : 1.056200, loss_ce: 2.002926, loss_dice: 0.819518
[02:47:14.977] iteration 71 : loss : 1.158726, loss_ce: 2.314788, loss_dice: 0.869710
[02:47:15.057] iteration 72 : loss : 1.143512, loss_ce: 2.215259, loss_dice: 0.875575
[02:47:15.139] iteration 73 : loss : 1.027890, loss_ce: 1.651287, loss_dice: 0.872040
[02:47:15.223] iteration 74 : loss : 1.071174, loss_ce: 1.861371, loss_dice: 0.873625
[02:47:15.302] iteration 75 : loss : 1.137294, loss_ce: 2.249226, loss_dice: 0.859312
[02:47:15.382] iteration 76 : loss : 1.100630, loss_ce: 2.029915, loss_dice: 0.868309
[02:47:15.469] iteration 77 : loss : 1.152651, loss_ce: 2.266742, loss_dice: 0.874129
[02:47:15.550] iteration 78 : loss : 1.121011, loss_ce: 2.161520, loss_dice: 0.860884
[02:47:15.628] iteration 79 : loss : 1.119497, loss_ce: 2.127443, loss_dice: 0.867510
[02:47:15.708] iteration 80 : loss : 1.066986, loss_ce: 1.897587, loss_dice: 0.859336
[02:47:15.798] iteration 81 : loss : 1.154303, loss_ce: 2.250931, loss_dice: 0.880146
[02:47:15.877] iteration 82 : loss : 1.110825, loss_ce: 2.086106, loss_dice: 0.867005
[02:47:15.955] iteration 83 : loss : 1.147741, loss_ce: 2.272697, loss_dice: 0.866503
[02:47:16.035] iteration 84 : loss : 1.114121, loss_ce: 2.062689, loss_dice: 0.876979
[02:47:16.116] iteration 85 : loss : 1.114244, loss_ce: 2.055480, loss_dice: 0.878936
[02:47:16.200] iteration 86 : loss : 1.101949, loss_ce: 1.988154, loss_dice: 0.880398
[02:47:16.284] iteration 87 : loss : 1.080152, loss_ce: 1.916084, loss_dice: 0.871169
[02:47:16.369] iteration 88 : loss : 1.143521, loss_ce: 2.220385, loss_dice: 0.874305
[02:47:16.462] iteration 89 : loss : 1.116166, loss_ce: 2.116048, loss_dice: 0.866195
[02:47:16.549] iteration 90 : loss : 1.056056, loss_ce: 1.810778, loss_dice: 0.867376
[02:47:16.635] iteration 91 : loss : 1.116009, loss_ce: 2.025150, loss_dice: 0.888724
[02:47:16.720] iteration 92 : loss : 1.081797, loss_ce: 1.906420, loss_dice: 0.875641
[02:47:16.802] iteration 93 : loss : 1.093688, loss_ce: 1.990116, loss_dice: 0.869581
[02:47:16.884] iteration 94 : loss : 1.089550, loss_ce: 1.980098, loss_dice: 0.866913
[02:47:16.965] iteration 95 : loss : 1.082494, loss_ce: 1.962720, loss_dice: 0.862437
[02:47:17.046] iteration 96 : loss : 1.113561, loss_ce: 2.137319, loss_dice: 0.857621
[02:47:17.128] iteration 97 : loss : 1.073330, loss_ce: 1.937554, loss_dice: 0.857274
[02:47:17.209] iteration 98 : loss : 1.084064, loss_ce: 1.976656, loss_dice: 0.860916
[02:47:17.289] iteration 99 : loss : 0.987580, loss_ce: 1.461678, loss_dice: 0.869056
[02:47:17.368] iteration 100 : loss : 1.110017, loss_ce: 2.107968, loss_dice: 0.860529
[02:47:17.467] iteration 101 : loss : 1.087749, loss_ce: 1.998299, loss_dice: 0.860112
[02:47:17.550] iteration 102 : loss : 1.060620, loss_ce: 1.886460, loss_dice: 0.854160
[02:47:17.633] iteration 103 : loss : 0.996930, loss_ce: 1.566950, loss_dice: 0.854425
[02:47:17.714] iteration 104 : loss : 1.075544, loss_ce: 1.924205, loss_dice: 0.863379
[02:47:17.795] iteration 105 : loss : 1.150023, loss_ce: 2.265165, loss_dice: 0.871237
[02:47:17.876] iteration 106 : loss : 1.024818, loss_ce: 1.656017, loss_dice: 0.867019
[02:47:17.958] iteration 107 : loss : 1.058949, loss_ce: 1.860582, loss_dice: 0.858541
[02:47:18.042] iteration 108 : loss : 1.058396, loss_ce: 1.857697, loss_dice: 0.858571
[02:47:18.124] iteration 109 : loss : 1.084288, loss_ce: 1.983362, loss_dice: 0.859519
[02:47:18.209] iteration 110 : loss : 1.049342, loss_ce: 1.797771, loss_dice: 0.862235
[02:47:18.290] iteration 111 : loss : 1.099102, loss_ce: 2.021359, loss_dice: 0.868537
[02:47:18.371] iteration 112 : loss : 1.091013, loss_ce: 1.934222, loss_dice: 0.880211
[02:47:18.451] iteration 113 : loss : 1.116571, loss_ce: 2.055321, loss_dice: 0.881884
[02:47:18.531] iteration 114 : loss : 1.078886, loss_ce: 1.930431, loss_dice: 0.865999
[02:47:18.613] iteration 115 : loss : 1.103500, loss_ce: 2.059968, loss_dice: 0.864382
[02:47:18.694] iteration 116 : loss : 1.097585, loss_ce: 2.064061, loss_dice: 0.855966
[02:47:18.774] iteration 117 : loss : 1.097820, loss_ce: 2.056745, loss_dice: 0.858089
[02:47:18.857] iteration 118 : loss : 1.048074, loss_ce: 1.784620, loss_dice: 0.863937
[02:47:18.941] iteration 119 : loss : 1.106630, loss_ce: 2.098326, loss_dice: 0.858706
[02:47:19.024] iteration 120 : loss : 1.114359, loss_ce: 2.104949, loss_dice: 0.866711
[02:47:19.114] iteration 121 : loss : 1.028099, loss_ce: 1.687489, loss_dice: 0.863251
[02:47:19.196] iteration 122 : loss : 1.071628, loss_ce: 1.837708, loss_dice: 0.880108
[02:47:19.278] iteration 123 : loss : 1.138680, loss_ce: 2.218996, loss_dice: 0.868601
[02:47:19.357] iteration 124 : loss : 1.084545, loss_ce: 2.027441, loss_dice: 0.848821
[02:47:19.440] iteration 125 : loss : 1.049389, loss_ce: 1.816137, loss_dice: 0.857702
[02:47:19.521] iteration 126 : loss : 1.115387, loss_ce: 2.128983, loss_dice: 0.861988
[02:47:19.603] iteration 127 : loss : 1.095297, loss_ce: 1.991276, loss_dice: 0.871302
[02:47:19.686] iteration 128 : loss : 1.040750, loss_ce: 1.762414, loss_dice: 0.860334
[02:47:19.768] iteration 129 : loss : 1.081412, loss_ce: 1.914248, loss_dice: 0.873203
[02:47:19.850] iteration 130 : loss : 1.076281, loss_ce: 1.919973, loss_dice: 0.865358
[02:47:19.933] iteration 131 : loss : 1.127190, loss_ce: 2.221711, loss_dice: 0.853560
[02:47:20.014] iteration 132 : loss : 1.142622, loss_ce: 2.261372, loss_dice: 0.862934
[02:47:20.098] iteration 133 : loss : 1.045179, loss_ce: 1.805809, loss_dice: 0.855021
[02:47:20.182] iteration 134 : loss : 1.079881, loss_ce: 1.909706, loss_dice: 0.872425
[02:47:20.265] iteration 135 : loss : 1.046938, loss_ce: 1.769293, loss_dice: 0.866349
[02:47:20.347] iteration 136 : loss : 1.170161, loss_ce: 2.330255, loss_dice: 0.880138
[02:47:20.427] iteration 137 : loss : 1.040492, loss_ce: 1.761736, loss_dice: 0.860181
[02:47:20.509] iteration 138 : loss : 1.025541, loss_ce: 1.707590, loss_dice: 0.855028
[02:47:20.588] iteration 139 : loss : 1.152606, loss_ce: 2.328717, loss_dice: 0.858578
[02:47:20.667] iteration 140 : loss : 0.999143, loss_ce: 1.548221, loss_dice: 0.861874
[02:47:20.758] iteration 141 : loss : 1.088563, loss_ce: 1.933435, loss_dice: 0.877345
[02:47:20.837] iteration 142 : loss : 1.099983, loss_ce: 1.971688, loss_dice: 0.882057
[02:47:20.917] iteration 143 : loss : 1.134317, loss_ce: 2.182372, loss_dice: 0.872303
[02:47:21.001] iteration 144 : loss : 1.090115, loss_ce: 1.987153, loss_dice: 0.865856
[02:47:21.088] iteration 145 : loss : 1.127184, loss_ce: 2.228859, loss_dice: 0.851765
[02:47:21.171] iteration 146 : loss : 1.123990, loss_ce: 2.128383, loss_dice: 0.872891
[02:47:21.251] iteration 147 : loss : 1.224192, loss_ce: 2.556731, loss_dice: 0.891057
[02:47:21.345] iteration 148 : loss : 1.094668, loss_ce: 2.051733, loss_dice: 0.855401
[02:47:21.425] iteration 149 : loss : 1.131567, loss_ce: 2.201651, loss_dice: 0.864046
[02:47:21.509] iteration 150 : loss : 1.099184, loss_ce: 2.068033, loss_dice: 0.856972
[02:47:21.593] iteration 151 : loss : 1.094027, loss_ce: 1.981624, loss_dice: 0.872128
[02:47:21.678] iteration 152 : loss : 1.066184, loss_ce: 1.842981, loss_dice: 0.871985
[02:47:21.759] iteration 153 : loss : 1.095328, loss_ce: 2.043012, loss_dice: 0.858407
[02:47:21.841] iteration 154 : loss : 1.006188, loss_ce: 1.657290, loss_dice: 0.843412
[02:47:21.924] iteration 155 : loss : 1.063842, loss_ce: 1.869010, loss_dice: 0.862550
[02:47:22.005] iteration 156 : loss : 1.057629, loss_ce: 1.872349, loss_dice: 0.853949
[02:47:22.088] iteration 157 : loss : 1.056887, loss_ce: 1.872305, loss_dice: 0.853033
[02:47:22.169] iteration 158 : loss : 1.065560, loss_ce: 1.887531, loss_dice: 0.860068
[02:47:22.252] iteration 159 : loss : 1.121283, loss_ce: 2.131692, loss_dice: 0.868681
[02:47:22.333] iteration 160 : loss : 0.995529, loss_ce: 1.588963, loss_dice: 0.847171
[02:47:22.427] iteration 161 : loss : 1.016524, loss_ce: 1.829760, loss_dice: 0.813215
[02:47:22.509] iteration 162 : loss : 1.104232, loss_ce: 2.089580, loss_dice: 0.857895
[02:47:22.590] iteration 163 : loss : 1.165838, loss_ce: 2.415436, loss_dice: 0.853439
[02:47:22.670] iteration 164 : loss : 1.084239, loss_ce: 2.094281, loss_dice: 0.831729
[02:47:22.751] iteration 165 : loss : 1.058556, loss_ce: 2.042893, loss_dice: 0.812472
[02:47:22.834] iteration 166 : loss : 1.075780, loss_ce: 1.921907, loss_dice: 0.864248
[02:47:22.915] iteration 167 : loss : 1.128538, loss_ce: 2.180425, loss_dice: 0.865566
[02:47:22.994] iteration 168 : loss : 1.066969, loss_ce: 1.840811, loss_dice: 0.873509
[02:47:23.076] iteration 169 : loss : 1.120577, loss_ce: 2.193918, loss_dice: 0.852242
[02:47:23.161] iteration 170 : loss : 1.034459, loss_ce: 1.754043, loss_dice: 0.854563
[02:47:23.245] iteration 171 : loss : 1.099182, loss_ce: 2.089578, loss_dice: 0.851582
[02:47:23.330] iteration 172 : loss : 1.110606, loss_ce: 2.122752, loss_dice: 0.857569
[02:47:23.415] iteration 173 : loss : 1.019133, loss_ce: 1.725794, loss_dice: 0.842468
[02:47:23.498] iteration 174 : loss : 1.052559, loss_ce: 1.866960, loss_dice: 0.848959
[02:47:23.581] iteration 175 : loss : 0.986680, loss_ce: 1.501850, loss_dice: 0.857887
[02:47:23.665] iteration 176 : loss : 1.098208, loss_ce: 2.026852, loss_dice: 0.866047
[02:47:23.746] iteration 177 : loss : 1.088174, loss_ce: 1.947751, loss_dice: 0.873280
[02:47:23.827] iteration 178 : loss : 1.085879, loss_ce: 1.951596, loss_dice: 0.869450
[02:47:23.910] iteration 179 : loss : 1.003785, loss_ce: 1.627406, loss_dice: 0.847880
[02:47:23.991] iteration 180 : loss : 1.088241, loss_ce: 2.017900, loss_dice: 0.855826
[02:47:24.086] iteration 181 : loss : 1.017857, loss_ce: 1.659817, loss_dice: 0.857367
[02:47:24.167] iteration 182 : loss : 1.122916, loss_ce: 2.168545, loss_dice: 0.861509
[02:47:24.249] iteration 183 : loss : 1.003434, loss_ce: 1.588436, loss_dice: 0.857184
[02:47:24.330] iteration 184 : loss : 1.039495, loss_ce: 1.738969, loss_dice: 0.864627
[02:47:24.414] iteration 185 : loss : 1.089253, loss_ce: 2.052536, loss_dice: 0.848432
[02:47:24.500] iteration 186 : loss : 1.088728, loss_ce: 2.021351, loss_dice: 0.855572
[02:47:24.586] iteration 187 : loss : 1.103678, loss_ce: 2.072986, loss_dice: 0.861351
[02:47:24.672] iteration 188 : loss : 1.025251, loss_ce: 1.710923, loss_dice: 0.853833
[02:47:24.756] iteration 189 : loss : 1.011777, loss_ce: 1.647593, loss_dice: 0.852823
[02:47:24.839] iteration 190 : loss : 1.128738, loss_ce: 2.240234, loss_dice: 0.850864
[02:47:24.922] iteration 191 : loss : 1.055272, loss_ce: 1.918453, loss_dice: 0.839477
[02:47:25.004] iteration 192 : loss : 1.095875, loss_ce: 2.011225, loss_dice: 0.867038
[02:47:25.088] iteration 193 : loss : 1.091958, loss_ce: 2.009042, loss_dice: 0.862687
[02:47:25.172] iteration 194 : loss : 1.039167, loss_ce: 1.781069, loss_dice: 0.853691
[02:47:25.257] iteration 195 : loss : 1.110514, loss_ce: 2.048269, loss_dice: 0.876075
[02:47:25.343] iteration 196 : loss : 1.042114, loss_ce: 1.798626, loss_dice: 0.852986
[02:47:25.431] iteration 197 : loss : 1.025871, loss_ce: 1.637024, loss_dice: 0.873083
[02:47:25.518] iteration 198 : loss : 1.096484, loss_ce: 2.042729, loss_dice: 0.859923
[02:47:25.605] iteration 199 : loss : 1.107941, loss_ce: 2.095254, loss_dice: 0.861113
[02:47:25.690] iteration 200 : loss : 1.083870, loss_ce: 1.971248, loss_dice: 0.862025
[02:47:25.786] iteration 201 : loss : 1.086591, loss_ce: 2.008587, loss_dice: 0.856092
[02:47:25.869] iteration 202 : loss : 1.070903, loss_ce: 1.934147, loss_dice: 0.855092
[02:47:25.953] iteration 203 : loss : 1.056171, loss_ce: 1.857750, loss_dice: 0.855776
[02:47:26.037] iteration 204 : loss : 1.034355, loss_ce: 1.764694, loss_dice: 0.851771
[02:47:26.121] iteration 205 : loss : 1.035079, loss_ce: 1.749023, loss_dice: 0.856593
[02:47:26.203] iteration 206 : loss : 1.043602, loss_ce: 1.836202, loss_dice: 0.845452
[02:47:26.285] iteration 207 : loss : 1.004246, loss_ce: 1.631772, loss_dice: 0.847365
[02:47:26.366] iteration 208 : loss : 1.103350, loss_ce: 2.153354, loss_dice: 0.840849
[02:47:26.450] iteration 209 : loss : 1.038321, loss_ce: 1.847263, loss_dice: 0.836085
[02:47:26.532] iteration 210 : loss : 1.213777, loss_ce: 2.531832, loss_dice: 0.884263
[02:47:26.613] iteration 211 : loss : 1.014796, loss_ce: 1.647753, loss_dice: 0.856557
[02:47:26.695] iteration 212 : loss : 1.123255, loss_ce: 2.180760, loss_dice: 0.858879
[02:47:26.777] iteration 213 : loss : 1.062731, loss_ce: 1.867324, loss_dice: 0.861582
[02:47:26.858] iteration 214 : loss : 1.107354, loss_ce: 2.070571, loss_dice: 0.866550
[02:47:26.938] iteration 215 : loss : 1.068355, loss_ce: 1.863915, loss_dice: 0.869465
[02:47:27.019] iteration 216 : loss : 0.934942, loss_ce: 1.195516, loss_dice: 0.869798
[02:47:27.100] iteration 217 : loss : 1.022880, loss_ce: 1.619530, loss_dice: 0.873717
[02:47:27.182] iteration 218 : loss : 1.062137, loss_ce: 1.811660, loss_dice: 0.874756
[02:47:27.261] iteration 219 : loss : 1.062218, loss_ce: 1.894736, loss_dice: 0.854088
[02:47:27.341] iteration 220 : loss : 1.109582, loss_ce: 2.076141, loss_dice: 0.867942
[02:47:27.431] iteration 221 : loss : 1.037253, loss_ce: 1.720658, loss_dice: 0.866402
[02:47:27.517] iteration 222 : loss : 1.049456, loss_ce: 1.821575, loss_dice: 0.856427
[02:47:27.596] iteration 223 : loss : 1.105506, loss_ce: 2.093067, loss_dice: 0.858615
[02:47:27.678] iteration 224 : loss : 1.082326, loss_ce: 2.066323, loss_dice: 0.836326
[02:47:27.759] iteration 225 : loss : 1.074963, loss_ce: 1.996035, loss_dice: 0.844695
[02:47:27.844] iteration 226 : loss : 1.030840, loss_ce: 1.781020, loss_dice: 0.843295
[02:47:27.924] iteration 227 : loss : 0.982939, loss_ce: 1.505504, loss_dice: 0.852298
[02:47:28.003] iteration 228 : loss : 1.010020, loss_ce: 1.586856, loss_dice: 0.865811
[02:47:28.085] iteration 229 : loss : 1.055597, loss_ce: 1.834974, loss_dice: 0.860752
[02:47:28.167] iteration 230 : loss : 1.087697, loss_ce: 1.983387, loss_dice: 0.863775
[02:47:28.247] iteration 231 : loss : 1.068986, loss_ce: 1.890635, loss_dice: 0.863574
[02:47:28.327] iteration 232 : loss : 1.022576, loss_ce: 1.687577, loss_dice: 0.856325
[02:47:28.408] iteration 233 : loss : 1.134558, loss_ce: 2.237983, loss_dice: 0.858702
[02:47:28.488] iteration 234 : loss : 1.072539, loss_ce: 1.941320, loss_dice: 0.855344
[02:47:28.569] iteration 235 : loss : 1.069276, loss_ce: 1.930326, loss_dice: 0.854013
[02:47:28.650] iteration 236 : loss : 1.004799, loss_ce: 1.639814, loss_dice: 0.846045
[02:47:28.731] iteration 237 : loss : 0.955791, loss_ce: 1.377240, loss_dice: 0.850429
[02:47:28.813] iteration 238 : loss : 1.094009, loss_ce: 1.974582, loss_dice: 0.873866
[02:47:28.894] iteration 239 : loss : 1.111902, loss_ce: 2.102699, loss_dice: 0.864203
[02:47:28.977] iteration 240 : loss : 1.097117, loss_ce: 2.001372, loss_dice: 0.871054
[02:47:29.069] iteration 241 : loss : 1.014268, loss_ce: 1.695998, loss_dice: 0.843835
[02:47:29.153] iteration 242 : loss : 0.959672, loss_ce: 1.394365, loss_dice: 0.850999
[02:47:29.236] iteration 243 : loss : 1.100829, loss_ce: 2.050725, loss_dice: 0.863355
[02:47:29.317] iteration 244 : loss : 1.047550, loss_ce: 1.836776, loss_dice: 0.850244
[02:47:29.405] iteration 245 : loss : 1.031179, loss_ce: 1.735448, loss_dice: 0.855112
[02:47:29.487] iteration 246 : loss : 1.168262, loss_ce: 2.354357, loss_dice: 0.871738
[02:47:29.570] iteration 247 : loss : 1.093724, loss_ce: 2.062834, loss_dice: 0.851447
[02:47:29.657] iteration 248 : loss : 1.056202, loss_ce: 1.818648, loss_dice: 0.865591
[02:47:29.740] iteration 249 : loss : 1.025827, loss_ce: 1.756585, loss_dice: 0.843138
[02:47:29.824] iteration 250 : loss : 0.921235, loss_ce: 1.171331, loss_dice: 0.858711
[02:47:29.910] iteration 251 : loss : 1.227957, loss_ce: 2.585882, loss_dice: 0.888476
[02:47:29.993] iteration 252 : loss : 1.069303, loss_ce: 1.888098, loss_dice: 0.864604
[02:47:30.078] iteration 253 : loss : 1.093558, loss_ce: 1.946686, loss_dice: 0.880276
[02:47:30.166] iteration 254 : loss : 1.119286, loss_ce: 2.150969, loss_dice: 0.861366
[02:47:30.251] iteration 255 : loss : 1.154718, loss_ce: 2.306712, loss_dice: 0.866720
[02:47:30.336] iteration 256 : loss : 1.319958, loss_ce: 3.097195, loss_dice: 0.875649
[02:47:30.420] iteration 257 : loss : 1.141327, loss_ce: 2.212793, loss_dice: 0.873460
[02:47:30.501] iteration 258 : loss : 1.139351, loss_ce: 2.199620, loss_dice: 0.874284
[02:47:30.584] iteration 259 : loss : 1.143484, loss_ce: 2.249842, loss_dice: 0.866894
[02:47:30.668] iteration 260 : loss : 1.188699, loss_ce: 2.415084, loss_dice: 0.882103
[02:47:30.763] iteration 261 : loss : 1.086048, loss_ce: 1.928883, loss_dice: 0.875339
[02:47:30.844] iteration 262 : loss : 1.133758, loss_ce: 2.158731, loss_dice: 0.877514
[08:45:45.817] Namespace(AdamW=True, base_lr=0.005, batch_size=6, ckpt='checkpoints/sam_vit_b_01ec64.pth', dataset='Synapse', deterministic=1, dice_param=0.8, exp='Synapse_128', img_size=128, is_pretrain=True, list_dir='./lists/lists_PASTIS', lora_ckpt=None, max_epochs=200, max_iterations=30000, module='sam_lora_image_encoder', n_gpu=1, num_classes=20, num_workers=0, output='/home/narvjes/repos/SAMed-jnar/output', rank=4, root_path='/home/narvjes/data/PASTIS/SAMed', seed=1234, stop_epoch=200, vit_name='vit_b', warmup=True, warmup_period=250)
[08:45:45.821] 406 iterations per epoch. 81200 max iterations 
[08:45:45.966] iteration 1 : loss : 1.465543, loss_ce: 3.550925, loss_dice: 0.944198
[08:45:46.056] iteration 2 : loss : 1.363455, loss_ce: 3.038692, loss_dice: 0.944645
[08:45:46.143] iteration 3 : loss : 1.377217, loss_ce: 3.059498, loss_dice: 0.956647
[08:45:46.229] iteration 4 : loss : 1.298359, loss_ce: 2.746732, loss_dice: 0.936266
[08:45:46.313] iteration 5 : loss : 1.210821, loss_ce: 2.343660, loss_dice: 0.927611
[08:45:46.397] iteration 6 : loss : 1.274644, loss_ce: 2.633682, loss_dice: 0.934885
[08:45:46.482] iteration 7 : loss : 1.304172, loss_ce: 2.759356, loss_dice: 0.940376
[08:45:46.569] iteration 8 : loss : 1.183288, loss_ce: 2.195310, loss_dice: 0.930282
[08:45:46.655] iteration 9 : loss : 1.166242, loss_ce: 2.112755, loss_dice: 0.929614
[08:45:46.737] iteration 10 : loss : 1.170338, loss_ce: 2.096336, loss_dice: 0.938839
[08:45:46.822] iteration 11 : loss : 1.100731, loss_ce: 1.789319, loss_dice: 0.928584
[08:45:46.904] iteration 12 : loss : 1.217200, loss_ce: 2.341969, loss_dice: 0.936007
[08:45:46.989] iteration 13 : loss : 1.185126, loss_ce: 2.178775, loss_dice: 0.936713
[08:45:47.072] iteration 14 : loss : 1.188387, loss_ce: 2.251999, loss_dice: 0.922485
[08:45:47.157] iteration 15 : loss : 1.227229, loss_ce: 2.422162, loss_dice: 0.928496
[08:45:47.242] iteration 16 : loss : 1.221668, loss_ce: 2.415066, loss_dice: 0.923319
[08:45:47.324] iteration 17 : loss : 1.151816, loss_ce: 2.065614, loss_dice: 0.923366
[08:45:47.408] iteration 18 : loss : 1.126015, loss_ce: 1.946822, loss_dice: 0.920813
[08:45:47.493] iteration 19 : loss : 1.116235, loss_ce: 1.847660, loss_dice: 0.933378
[08:45:47.576] iteration 20 : loss : 1.170058, loss_ce: 2.132311, loss_dice: 0.929494
[08:45:47.672] iteration 21 : loss : 1.128037, loss_ce: 1.908427, loss_dice: 0.932940
[08:45:47.758] iteration 22 : loss : 1.106202, loss_ce: 1.817472, loss_dice: 0.928384
[08:45:47.840] iteration 23 : loss : 1.187609, loss_ce: 2.216669, loss_dice: 0.930344
[08:45:47.923] iteration 24 : loss : 1.163294, loss_ce: 2.110465, loss_dice: 0.926501
[08:45:48.008] iteration 25 : loss : 1.107252, loss_ce: 1.833154, loss_dice: 0.925776
[08:45:48.093] iteration 26 : loss : 1.158281, loss_ce: 2.074564, loss_dice: 0.929211
[08:45:48.178] iteration 27 : loss : 1.184233, loss_ce: 2.214813, loss_dice: 0.926588
[08:45:48.262] iteration 28 : loss : 1.244601, loss_ce: 2.492827, loss_dice: 0.932544
[08:45:48.345] iteration 29 : loss : 1.122555, loss_ce: 1.916764, loss_dice: 0.924003
[08:45:48.428] iteration 30 : loss : 1.108063, loss_ce: 1.846163, loss_dice: 0.923538
[08:45:48.511] iteration 31 : loss : 1.182201, loss_ce: 2.200346, loss_dice: 0.927665
[08:45:48.595] iteration 32 : loss : 1.130089, loss_ce: 1.948198, loss_dice: 0.925562
[08:45:48.679] iteration 33 : loss : 1.122598, loss_ce: 1.946282, loss_dice: 0.916677
[08:45:48.764] iteration 34 : loss : 1.169749, loss_ce: 2.232080, loss_dice: 0.904167
[08:45:48.847] iteration 35 : loss : 1.082965, loss_ce: 1.903018, loss_dice: 0.877952
[08:45:48.929] iteration 36 : loss : 1.108794, loss_ce: 2.043901, loss_dice: 0.875017
[08:45:49.012] iteration 37 : loss : 1.089401, loss_ce: 1.935133, loss_dice: 0.877967
[08:45:49.096] iteration 38 : loss : 1.155999, loss_ce: 2.264166, loss_dice: 0.878957
[08:45:49.178] iteration 39 : loss : 1.066104, loss_ce: 1.823189, loss_dice: 0.876833
[08:45:49.264] iteration 40 : loss : 1.058176, loss_ce: 1.786453, loss_dice: 0.876107
[08:45:49.356] iteration 41 : loss : 1.085728, loss_ce: 1.923271, loss_dice: 0.876343
[08:45:49.436] iteration 42 : loss : 1.097906, loss_ce: 1.978575, loss_dice: 0.877739
[08:45:49.518] iteration 43 : loss : 1.098510, loss_ce: 1.986581, loss_dice: 0.876492
[08:45:49.601] iteration 44 : loss : 1.069930, loss_ce: 1.857296, loss_dice: 0.873088
[08:45:49.686] iteration 45 : loss : 1.095182, loss_ce: 1.952454, loss_dice: 0.880864
[08:45:49.769] iteration 46 : loss : 1.130174, loss_ce: 2.183167, loss_dice: 0.866926
[08:45:49.852] iteration 47 : loss : 1.122566, loss_ce: 2.233894, loss_dice: 0.844734
[08:45:49.934] iteration 48 : loss : 1.104245, loss_ce: 2.020504, loss_dice: 0.875180
[08:45:50.017] iteration 49 : loss : 1.151837, loss_ce: 2.269504, loss_dice: 0.872421
[08:45:50.099] iteration 50 : loss : 1.040428, loss_ce: 1.691774, loss_dice: 0.877592
[08:45:50.182] iteration 51 : loss : 1.109556, loss_ce: 2.030433, loss_dice: 0.879337
[08:45:50.266] iteration 52 : loss : 1.018866, loss_ce: 1.568945, loss_dice: 0.881347
[08:45:50.348] iteration 53 : loss : 1.148580, loss_ce: 2.405953, loss_dice: 0.834237
[08:45:50.430] iteration 54 : loss : 1.063734, loss_ce: 2.015697, loss_dice: 0.825744
[08:45:50.512] iteration 55 : loss : 1.123463, loss_ce: 2.115726, loss_dice: 0.875397
[08:45:50.596] iteration 56 : loss : 1.127405, loss_ce: 2.159697, loss_dice: 0.869332
[08:45:50.678] iteration 57 : loss : 1.125407, loss_ce: 2.140193, loss_dice: 0.871710
[08:45:50.758] iteration 58 : loss : 1.108119, loss_ce: 2.214997, loss_dice: 0.831399
[08:45:50.840] iteration 59 : loss : 1.148155, loss_ce: 2.260632, loss_dice: 0.870036
[08:45:50.922] iteration 60 : loss : 1.101269, loss_ce: 2.202070, loss_dice: 0.826068
[08:45:51.014] iteration 61 : loss : 1.152523, loss_ce: 2.293223, loss_dice: 0.867347
[08:45:51.095] iteration 62 : loss : 1.033751, loss_ce: 1.669412, loss_dice: 0.874836
[08:45:51.176] iteration 63 : loss : 1.122884, loss_ce: 2.272173, loss_dice: 0.835562
[08:45:51.257] iteration 64 : loss : 1.111519, loss_ce: 2.040389, loss_dice: 0.879301
[08:45:51.339] iteration 65 : loss : 1.159415, loss_ce: 2.351143, loss_dice: 0.861483
[08:45:51.422] iteration 66 : loss : 1.142673, loss_ce: 2.232997, loss_dice: 0.870092
[08:45:51.505] iteration 67 : loss : 1.111116, loss_ce: 2.056265, loss_dice: 0.874829
[08:45:51.589] iteration 68 : loss : 1.204472, loss_ce: 2.382911, loss_dice: 0.909862
[08:45:51.671] iteration 69 : loss : 1.106748, loss_ce: 2.042790, loss_dice: 0.872737
[08:45:51.753] iteration 70 : loss : 1.056200, loss_ce: 2.002926, loss_dice: 0.819518
[08:45:51.840] iteration 71 : loss : 1.158726, loss_ce: 2.314788, loss_dice: 0.869710
[08:45:51.922] iteration 72 : loss : 1.143512, loss_ce: 2.215259, loss_dice: 0.875575
[08:45:52.004] iteration 73 : loss : 1.027889, loss_ce: 1.651287, loss_dice: 0.872040
[08:45:52.087] iteration 74 : loss : 1.071174, loss_ce: 1.861370, loss_dice: 0.873625
[08:45:52.168] iteration 75 : loss : 1.137294, loss_ce: 2.249226, loss_dice: 0.859312
[08:45:52.250] iteration 76 : loss : 1.100630, loss_ce: 2.029915, loss_dice: 0.868309
[08:45:52.333] iteration 77 : loss : 1.152651, loss_ce: 2.266742, loss_dice: 0.874129
[08:45:52.419] iteration 78 : loss : 1.121011, loss_ce: 2.161520, loss_dice: 0.860884
[08:45:52.501] iteration 79 : loss : 1.119497, loss_ce: 2.127443, loss_dice: 0.867510
[08:45:52.584] iteration 80 : loss : 1.066986, loss_ce: 1.897587, loss_dice: 0.859336
[08:45:52.677] iteration 81 : loss : 1.154303, loss_ce: 2.250931, loss_dice: 0.880146
[08:45:52.758] iteration 82 : loss : 1.110825, loss_ce: 2.086106, loss_dice: 0.867005
[08:45:52.839] iteration 83 : loss : 1.147741, loss_ce: 2.272697, loss_dice: 0.866503
[08:45:52.921] iteration 84 : loss : 1.114121, loss_ce: 2.062689, loss_dice: 0.876979
[08:45:53.002] iteration 85 : loss : 1.114245, loss_ce: 2.055480, loss_dice: 0.878936
[08:45:53.086] iteration 86 : loss : 1.101949, loss_ce: 1.988154, loss_dice: 0.880398
[08:45:53.169] iteration 87 : loss : 1.080152, loss_ce: 1.916084, loss_dice: 0.871169
[08:45:53.251] iteration 88 : loss : 1.143521, loss_ce: 2.220385, loss_dice: 0.874305
[08:45:53.334] iteration 89 : loss : 1.116166, loss_ce: 2.116048, loss_dice: 0.866195
[08:45:53.415] iteration 90 : loss : 1.056056, loss_ce: 1.810778, loss_dice: 0.867376
[08:45:53.496] iteration 91 : loss : 1.116009, loss_ce: 2.025150, loss_dice: 0.888724
[08:45:53.579] iteration 92 : loss : 1.081797, loss_ce: 1.906420, loss_dice: 0.875641
[08:45:53.660] iteration 93 : loss : 1.093688, loss_ce: 1.990116, loss_dice: 0.869581
[08:45:53.742] iteration 94 : loss : 1.089550, loss_ce: 1.980098, loss_dice: 0.866913
[08:45:53.823] iteration 95 : loss : 1.082494, loss_ce: 1.962720, loss_dice: 0.862437
[08:45:53.905] iteration 96 : loss : 1.113561, loss_ce: 2.137319, loss_dice: 0.857621
[08:45:53.989] iteration 97 : loss : 1.073330, loss_ce: 1.937554, loss_dice: 0.857274
[08:45:54.073] iteration 98 : loss : 1.084064, loss_ce: 1.976656, loss_dice: 0.860916
[08:45:54.155] iteration 99 : loss : 0.987580, loss_ce: 1.461678, loss_dice: 0.869056
[08:45:54.236] iteration 100 : loss : 1.110017, loss_ce: 2.107968, loss_dice: 0.860529
[08:45:54.331] iteration 101 : loss : 1.087749, loss_ce: 1.998299, loss_dice: 0.860112
[08:45:54.413] iteration 102 : loss : 1.060620, loss_ce: 1.886460, loss_dice: 0.854160
[08:45:54.496] iteration 103 : loss : 0.996930, loss_ce: 1.566950, loss_dice: 0.854425
[08:45:54.578] iteration 104 : loss : 1.075545, loss_ce: 1.924205, loss_dice: 0.863379
[08:45:54.661] iteration 105 : loss : 1.150023, loss_ce: 2.265165, loss_dice: 0.871237
[08:45:54.743] iteration 106 : loss : 1.024818, loss_ce: 1.656017, loss_dice: 0.867019
[08:45:54.823] iteration 107 : loss : 1.058949, loss_ce: 1.860582, loss_dice: 0.858541
[08:45:54.909] iteration 108 : loss : 1.058396, loss_ce: 1.857696, loss_dice: 0.858571
[08:45:54.991] iteration 109 : loss : 1.084288, loss_ce: 1.983362, loss_dice: 0.859519
[08:45:55.073] iteration 110 : loss : 1.049342, loss_ce: 1.797771, loss_dice: 0.862235
[08:45:55.156] iteration 111 : loss : 1.099102, loss_ce: 2.021358, loss_dice: 0.868537
[08:45:55.239] iteration 112 : loss : 1.091013, loss_ce: 1.934222, loss_dice: 0.880211
[08:45:55.320] iteration 113 : loss : 1.116571, loss_ce: 2.055321, loss_dice: 0.881884
[08:45:55.400] iteration 114 : loss : 1.078886, loss_ce: 1.930431, loss_dice: 0.865999
[08:45:55.481] iteration 115 : loss : 1.103499, loss_ce: 2.059968, loss_dice: 0.864382
[08:45:55.561] iteration 116 : loss : 1.097585, loss_ce: 2.064061, loss_dice: 0.855966
[08:45:55.641] iteration 117 : loss : 1.097820, loss_ce: 2.056745, loss_dice: 0.858089
[08:45:55.723] iteration 118 : loss : 1.048074, loss_ce: 1.784620, loss_dice: 0.863937
[08:45:55.804] iteration 119 : loss : 1.106630, loss_ce: 2.098326, loss_dice: 0.858706
[08:45:55.887] iteration 120 : loss : 1.114359, loss_ce: 2.104949, loss_dice: 0.866711
[08:45:55.978] iteration 121 : loss : 1.028099, loss_ce: 1.687489, loss_dice: 0.863251
[08:45:56.061] iteration 122 : loss : 1.071628, loss_ce: 1.837708, loss_dice: 0.880108
[08:45:56.144] iteration 123 : loss : 1.138680, loss_ce: 2.218997, loss_dice: 0.868601
[08:45:56.224] iteration 124 : loss : 1.084545, loss_ce: 2.027441, loss_dice: 0.848821
[08:45:56.306] iteration 125 : loss : 1.049389, loss_ce: 1.816137, loss_dice: 0.857702
[08:45:56.387] iteration 126 : loss : 1.115387, loss_ce: 2.128984, loss_dice: 0.861988
[08:45:56.469] iteration 127 : loss : 1.095297, loss_ce: 1.991276, loss_dice: 0.871302
[08:45:56.549] iteration 128 : loss : 1.040750, loss_ce: 1.762414, loss_dice: 0.860334
[08:45:56.631] iteration 129 : loss : 1.081412, loss_ce: 1.914248, loss_dice: 0.873203
[08:45:56.714] iteration 130 : loss : 1.076281, loss_ce: 1.919973, loss_dice: 0.865358
[08:45:56.797] iteration 131 : loss : 1.127190, loss_ce: 2.221711, loss_dice: 0.853560
[08:45:56.878] iteration 132 : loss : 1.142622, loss_ce: 2.261372, loss_dice: 0.862934
[08:45:56.961] iteration 133 : loss : 1.045179, loss_ce: 1.805809, loss_dice: 0.855021
[08:45:57.044] iteration 134 : loss : 1.079881, loss_ce: 1.909706, loss_dice: 0.872425
[08:45:57.127] iteration 135 : loss : 1.046938, loss_ce: 1.769293, loss_dice: 0.866349
[08:45:57.210] iteration 136 : loss : 1.170161, loss_ce: 2.330255, loss_dice: 0.880138
[08:45:57.291] iteration 137 : loss : 1.040492, loss_ce: 1.761735, loss_dice: 0.860181
[08:45:57.373] iteration 138 : loss : 1.025541, loss_ce: 1.707590, loss_dice: 0.855028
[08:45:57.453] iteration 139 : loss : 1.152606, loss_ce: 2.328717, loss_dice: 0.858578
[08:45:57.534] iteration 140 : loss : 0.999143, loss_ce: 1.548221, loss_dice: 0.861874
[08:45:57.625] iteration 141 : loss : 1.088563, loss_ce: 1.933435, loss_dice: 0.877345
[08:45:57.705] iteration 142 : loss : 1.099983, loss_ce: 1.971688, loss_dice: 0.882057
[08:45:57.787] iteration 143 : loss : 1.134317, loss_ce: 2.182372, loss_dice: 0.872303
[08:45:57.869] iteration 144 : loss : 1.090115, loss_ce: 1.987153, loss_dice: 0.865856
[08:45:57.953] iteration 145 : loss : 1.127184, loss_ce: 2.228859, loss_dice: 0.851765
[08:45:58.034] iteration 146 : loss : 1.123990, loss_ce: 2.128383, loss_dice: 0.872891
[08:45:58.114] iteration 147 : loss : 1.224192, loss_ce: 2.556731, loss_dice: 0.891057
[08:45:58.197] iteration 148 : loss : 1.094668, loss_ce: 2.051733, loss_dice: 0.855401
[08:45:58.278] iteration 149 : loss : 1.131567, loss_ce: 2.201651, loss_dice: 0.864046
[08:45:58.359] iteration 150 : loss : 1.099184, loss_ce: 2.068033, loss_dice: 0.856972
[08:45:58.441] iteration 151 : loss : 1.094027, loss_ce: 1.981624, loss_dice: 0.872128
[08:45:58.525] iteration 152 : loss : 1.066184, loss_ce: 1.842981, loss_dice: 0.871985
[08:45:58.606] iteration 153 : loss : 1.095328, loss_ce: 2.043012, loss_dice: 0.858407
[08:45:58.689] iteration 154 : loss : 1.006188, loss_ce: 1.657290, loss_dice: 0.843412
[08:45:58.771] iteration 155 : loss : 1.063842, loss_ce: 1.869010, loss_dice: 0.862550
[08:45:58.852] iteration 156 : loss : 1.057629, loss_ce: 1.872349, loss_dice: 0.853949
[08:45:58.934] iteration 157 : loss : 1.056887, loss_ce: 1.872305, loss_dice: 0.853033
[08:45:59.014] iteration 158 : loss : 1.065560, loss_ce: 1.887531, loss_dice: 0.860068
[08:45:59.097] iteration 159 : loss : 1.121283, loss_ce: 2.131692, loss_dice: 0.868681
[08:45:59.179] iteration 160 : loss : 0.995529, loss_ce: 1.588963, loss_dice: 0.847171
[08:45:59.271] iteration 161 : loss : 1.016524, loss_ce: 1.829760, loss_dice: 0.813215
[08:45:59.353] iteration 162 : loss : 1.104232, loss_ce: 2.089580, loss_dice: 0.857895
[08:45:59.433] iteration 163 : loss : 1.165838, loss_ce: 2.415436, loss_dice: 0.853439
[08:45:59.514] iteration 164 : loss : 1.084239, loss_ce: 2.094281, loss_dice: 0.831729
[08:45:59.595] iteration 165 : loss : 1.058556, loss_ce: 2.042893, loss_dice: 0.812472
[08:45:59.682] iteration 166 : loss : 1.075780, loss_ce: 1.921907, loss_dice: 0.864248
[08:45:59.763] iteration 167 : loss : 1.128538, loss_ce: 2.180425, loss_dice: 0.865566
[08:45:59.843] iteration 168 : loss : 1.066969, loss_ce: 1.840812, loss_dice: 0.873509
[08:45:59.924] iteration 169 : loss : 1.120577, loss_ce: 2.193918, loss_dice: 0.852242
[08:46:00.007] iteration 170 : loss : 1.034459, loss_ce: 1.754043, loss_dice: 0.854563
[08:46:00.086] iteration 171 : loss : 1.099182, loss_ce: 2.089578, loss_dice: 0.851582
[08:46:00.176] iteration 172 : loss : 1.110606, loss_ce: 2.122752, loss_dice: 0.857569
[08:46:00.261] iteration 173 : loss : 1.019133, loss_ce: 1.725794, loss_dice: 0.842468
[08:46:00.344] iteration 174 : loss : 1.052559, loss_ce: 1.866960, loss_dice: 0.848959
[08:46:00.428] iteration 175 : loss : 0.986680, loss_ce: 1.501850, loss_dice: 0.857887
[08:46:00.513] iteration 176 : loss : 1.098208, loss_ce: 2.026852, loss_dice: 0.866047
[08:46:00.596] iteration 177 : loss : 1.088174, loss_ce: 1.947751, loss_dice: 0.873280
[08:46:00.681] iteration 178 : loss : 1.085879, loss_ce: 1.951596, loss_dice: 0.869450
[08:46:00.766] iteration 179 : loss : 1.003785, loss_ce: 1.627406, loss_dice: 0.847880
[08:46:00.853] iteration 180 : loss : 1.088241, loss_ce: 2.017900, loss_dice: 0.855826
[08:46:00.950] iteration 181 : loss : 1.017857, loss_ce: 1.659817, loss_dice: 0.857367
[08:46:01.039] iteration 182 : loss : 1.122916, loss_ce: 2.168544, loss_dice: 0.861509
[08:46:01.131] iteration 183 : loss : 1.003434, loss_ce: 1.588436, loss_dice: 0.857184
[08:46:01.218] iteration 184 : loss : 1.039495, loss_ce: 1.738969, loss_dice: 0.864627
[08:46:01.301] iteration 185 : loss : 1.089253, loss_ce: 2.052536, loss_dice: 0.848432
[08:46:01.385] iteration 186 : loss : 1.088728, loss_ce: 2.021351, loss_dice: 0.855572
[08:46:01.468] iteration 187 : loss : 1.103678, loss_ce: 2.072986, loss_dice: 0.861351
[08:46:01.554] iteration 188 : loss : 1.025251, loss_ce: 1.710923, loss_dice: 0.853833
[08:46:01.637] iteration 189 : loss : 1.011777, loss_ce: 1.647593, loss_dice: 0.852823
[08:46:01.718] iteration 190 : loss : 1.128738, loss_ce: 2.240234, loss_dice: 0.850864
[08:46:01.808] iteration 191 : loss : 1.055272, loss_ce: 1.918453, loss_dice: 0.839477
[08:46:01.896] iteration 192 : loss : 1.095875, loss_ce: 2.011225, loss_dice: 0.867038
[08:46:01.986] iteration 193 : loss : 1.091958, loss_ce: 2.009042, loss_dice: 0.862687
[08:46:02.078] iteration 194 : loss : 1.039167, loss_ce: 1.781069, loss_dice: 0.853691
[08:46:02.169] iteration 195 : loss : 1.110514, loss_ce: 2.048269, loss_dice: 0.876075
[08:46:02.258] iteration 196 : loss : 1.042114, loss_ce: 1.798626, loss_dice: 0.852986
[08:46:02.347] iteration 197 : loss : 1.025871, loss_ce: 1.637024, loss_dice: 0.873083
[08:46:02.436] iteration 198 : loss : 1.096484, loss_ce: 2.042729, loss_dice: 0.859923
[08:46:02.524] iteration 199 : loss : 1.107941, loss_ce: 2.095254, loss_dice: 0.861113
[08:46:02.609] iteration 200 : loss : 1.083870, loss_ce: 1.971248, loss_dice: 0.862025
[08:46:02.703] iteration 201 : loss : 1.086591, loss_ce: 2.008587, loss_dice: 0.856092
[08:46:02.788] iteration 202 : loss : 1.070903, loss_ce: 1.934147, loss_dice: 0.855092
[08:46:02.872] iteration 203 : loss : 1.056171, loss_ce: 1.857750, loss_dice: 0.855776
[08:46:02.954] iteration 204 : loss : 1.034355, loss_ce: 1.764694, loss_dice: 0.851771
[08:46:03.037] iteration 205 : loss : 1.035079, loss_ce: 1.749023, loss_dice: 0.856593
[08:46:03.119] iteration 206 : loss : 1.043602, loss_ce: 1.836201, loss_dice: 0.845452
[08:46:03.202] iteration 207 : loss : 1.004246, loss_ce: 1.631772, loss_dice: 0.847365
[08:46:03.284] iteration 208 : loss : 1.103350, loss_ce: 2.153354, loss_dice: 0.840849
[08:46:03.367] iteration 209 : loss : 1.038321, loss_ce: 1.847263, loss_dice: 0.836085
[08:46:03.449] iteration 210 : loss : 1.213777, loss_ce: 2.531832, loss_dice: 0.884263
[08:46:03.531] iteration 211 : loss : 1.014796, loss_ce: 1.647753, loss_dice: 0.856557
[08:46:03.614] iteration 212 : loss : 1.123255, loss_ce: 2.180760, loss_dice: 0.858879
[08:46:03.696] iteration 213 : loss : 1.062731, loss_ce: 1.867324, loss_dice: 0.861582
[08:46:03.778] iteration 214 : loss : 1.107354, loss_ce: 2.070571, loss_dice: 0.866550
[08:46:03.859] iteration 215 : loss : 1.068355, loss_ce: 1.863915, loss_dice: 0.869465
[08:46:03.941] iteration 216 : loss : 0.934942, loss_ce: 1.195516, loss_dice: 0.869798
[08:46:04.023] iteration 217 : loss : 1.022880, loss_ce: 1.619531, loss_dice: 0.873717
[08:46:04.106] iteration 218 : loss : 1.062137, loss_ce: 1.811660, loss_dice: 0.874756
[08:46:04.188] iteration 219 : loss : 1.062218, loss_ce: 1.894736, loss_dice: 0.854088
[08:46:04.273] iteration 220 : loss : 1.109582, loss_ce: 2.076141, loss_dice: 0.867942
[08:46:04.366] iteration 221 : loss : 1.037253, loss_ce: 1.720658, loss_dice: 0.866402
[08:46:04.454] iteration 222 : loss : 1.049456, loss_ce: 1.821575, loss_dice: 0.856427
[08:46:04.535] iteration 223 : loss : 1.105506, loss_ce: 2.093067, loss_dice: 0.858615
[08:46:04.618] iteration 224 : loss : 1.082326, loss_ce: 2.066323, loss_dice: 0.836326
[08:46:04.699] iteration 225 : loss : 1.074963, loss_ce: 1.996035, loss_dice: 0.844695
[08:46:04.782] iteration 226 : loss : 1.030840, loss_ce: 1.781021, loss_dice: 0.843295
[08:46:04.866] iteration 227 : loss : 0.982939, loss_ce: 1.505504, loss_dice: 0.852298
[08:46:04.947] iteration 228 : loss : 1.010020, loss_ce: 1.586856, loss_dice: 0.865811
[08:46:05.030] iteration 229 : loss : 1.055597, loss_ce: 1.834974, loss_dice: 0.860752
[08:46:05.110] iteration 230 : loss : 1.087697, loss_ce: 1.983387, loss_dice: 0.863775
[08:46:05.192] iteration 231 : loss : 1.068986, loss_ce: 1.890635, loss_dice: 0.863574
[08:46:05.273] iteration 232 : loss : 1.022576, loss_ce: 1.687577, loss_dice: 0.856325
[08:46:05.355] iteration 233 : loss : 1.134558, loss_ce: 2.237983, loss_dice: 0.858702
[08:46:05.437] iteration 234 : loss : 1.072539, loss_ce: 1.941320, loss_dice: 0.855344
[08:46:05.520] iteration 235 : loss : 1.069276, loss_ce: 1.930327, loss_dice: 0.854013
[08:46:05.607] iteration 236 : loss : 1.004799, loss_ce: 1.639814, loss_dice: 0.846045
[08:46:05.692] iteration 237 : loss : 0.955792, loss_ce: 1.377240, loss_dice: 0.850429
[08:46:05.774] iteration 238 : loss : 1.094010, loss_ce: 1.974582, loss_dice: 0.873866
[08:46:05.855] iteration 239 : loss : 1.111902, loss_ce: 2.102699, loss_dice: 0.864203
[08:46:05.937] iteration 240 : loss : 1.097117, loss_ce: 2.001372, loss_dice: 0.871054
[08:46:06.032] iteration 241 : loss : 1.014268, loss_ce: 1.695998, loss_dice: 0.843835
[08:46:06.116] iteration 242 : loss : 0.959672, loss_ce: 1.394365, loss_dice: 0.850999
[08:46:06.200] iteration 243 : loss : 1.100829, loss_ce: 2.050725, loss_dice: 0.863355
[08:46:06.282] iteration 244 : loss : 1.047550, loss_ce: 1.836776, loss_dice: 0.850244
[08:46:06.366] iteration 245 : loss : 1.031179, loss_ce: 1.735448, loss_dice: 0.855112
[08:46:06.447] iteration 246 : loss : 1.168262, loss_ce: 2.354357, loss_dice: 0.871738
[08:46:06.528] iteration 247 : loss : 1.093724, loss_ce: 2.062834, loss_dice: 0.851447
[08:46:06.610] iteration 248 : loss : 1.056202, loss_ce: 1.818648, loss_dice: 0.865591
[08:46:06.690] iteration 249 : loss : 1.025827, loss_ce: 1.756585, loss_dice: 0.843138
[08:46:06.772] iteration 250 : loss : 0.921235, loss_ce: 1.171331, loss_dice: 0.858711
[08:46:06.861] iteration 251 : loss : 1.227957, loss_ce: 2.585882, loss_dice: 0.888476
[08:46:06.948] iteration 252 : loss : 1.069303, loss_ce: 1.888098, loss_dice: 0.864604
[08:46:07.033] iteration 253 : loss : 1.093558, loss_ce: 1.946686, loss_dice: 0.880276
[08:46:07.119] iteration 254 : loss : 1.119286, loss_ce: 2.150969, loss_dice: 0.861366
[08:46:07.206] iteration 255 : loss : 1.154718, loss_ce: 2.306712, loss_dice: 0.866720
[08:46:07.293] iteration 256 : loss : 1.319958, loss_ce: 3.097195, loss_dice: 0.875649
[08:46:07.379] iteration 257 : loss : 1.141327, loss_ce: 2.212793, loss_dice: 0.873460
[08:46:07.463] iteration 258 : loss : 1.139351, loss_ce: 2.199620, loss_dice: 0.874284
[08:46:07.547] iteration 259 : loss : 1.143484, loss_ce: 2.249842, loss_dice: 0.866894
[08:46:07.630] iteration 260 : loss : 1.188699, loss_ce: 2.415084, loss_dice: 0.882103
[08:46:07.727] iteration 261 : loss : 1.086048, loss_ce: 1.928883, loss_dice: 0.875339
[08:46:07.812] iteration 262 : loss : 1.133758, loss_ce: 2.158731, loss_dice: 0.877514
[08:46:07.895] iteration 263 : loss : 1.077789, loss_ce: 1.882040, loss_dice: 0.876726
[08:46:07.978] iteration 264 : loss : 1.106809, loss_ce: 2.012446, loss_dice: 0.880400
[08:46:08.061] iteration 265 : loss : 1.108105, loss_ce: 2.057492, loss_dice: 0.870758
[08:46:08.142] iteration 266 : loss : 1.230471, loss_ce: 2.647589, loss_dice: 0.876192
[08:46:08.225] iteration 267 : loss : 1.117880, loss_ce: 2.093885, loss_dice: 0.873879
[08:46:08.309] iteration 268 : loss : 1.100242, loss_ce: 1.992726, loss_dice: 0.877120
[08:46:08.392] iteration 269 : loss : 1.128943, loss_ce: 2.126859, loss_dice: 0.879465
[08:46:08.476] iteration 270 : loss : 1.158597, loss_ce: 2.275228, loss_dice: 0.879439
[08:46:08.560] iteration 271 : loss : 1.106514, loss_ce: 1.840532, loss_dice: 0.923010
[08:46:08.642] iteration 272 : loss : 1.067198, loss_ce: 1.826746, loss_dice: 0.877311
[08:46:08.725] iteration 273 : loss : 1.076693, loss_ce: 1.882939, loss_dice: 0.875131
[08:46:08.806] iteration 274 : loss : 1.025355, loss_ce: 1.602212, loss_dice: 0.881141
[08:46:08.888] iteration 275 : loss : 1.143516, loss_ce: 2.167931, loss_dice: 0.887412
[08:46:08.972] iteration 276 : loss : 1.165355, loss_ce: 2.301708, loss_dice: 0.881267
[08:46:09.058] iteration 277 : loss : 1.182216, loss_ce: 2.391968, loss_dice: 0.879777
[08:46:09.143] iteration 278 : loss : 1.064791, loss_ce: 1.821006, loss_dice: 0.875737
[08:46:09.229] iteration 279 : loss : 1.054147, loss_ce: 1.800857, loss_dice: 0.867469
[08:46:09.315] iteration 280 : loss : 1.094401, loss_ce: 1.917690, loss_dice: 0.888579
[08:46:09.411] iteration 281 : loss : 1.140764, loss_ce: 2.328511, loss_dice: 0.843827
[08:46:09.495] iteration 282 : loss : 1.092253, loss_ce: 2.100443, loss_dice: 0.840205
[08:46:09.579] iteration 283 : loss : 1.174301, loss_ce: 2.377499, loss_dice: 0.873502
[08:46:09.663] iteration 284 : loss : 1.182973, loss_ce: 2.398328, loss_dice: 0.879134
[08:46:09.747] iteration 285 : loss : 1.084319, loss_ce: 2.127216, loss_dice: 0.823595
[08:46:09.831] iteration 286 : loss : 1.123816, loss_ce: 2.310983, loss_dice: 0.827025
[08:46:09.915] iteration 287 : loss : 1.147961, loss_ce: 2.425412, loss_dice: 0.828598
[08:46:10.000] iteration 288 : loss : 1.116009, loss_ce: 2.070557, loss_dice: 0.877371
[08:46:10.082] iteration 289 : loss : 1.085200, loss_ce: 2.119688, loss_dice: 0.826578
[08:46:10.165] iteration 290 : loss : 1.060936, loss_ce: 1.762154, loss_dice: 0.885632
[08:46:10.248] iteration 291 : loss : 1.166704, loss_ce: 2.263092, loss_dice: 0.892607
[08:46:10.329] iteration 292 : loss : 1.003220, loss_ce: 1.702619, loss_dice: 0.828371
[08:46:10.413] iteration 293 : loss : 1.129641, loss_ce: 2.149932, loss_dice: 0.874568
[08:46:10.495] iteration 294 : loss : 1.123543, loss_ce: 2.138533, loss_dice: 0.869796
[08:46:10.577] iteration 295 : loss : 1.142138, loss_ce: 2.240468, loss_dice: 0.867556
[08:46:10.658] iteration 296 : loss : 6.293466, loss_ce: 27.675171, loss_dice: 0.948039
[08:46:10.740] iteration 297 : loss : 1.267341, loss_ce: 2.819394, loss_dice: 0.879327
[08:46:10.822] iteration 298 : loss : 1.545110, loss_ce: 4.087871, loss_dice: 0.909420
[08:46:10.904] iteration 299 : loss : 1.118962, loss_ce: 2.075491, loss_dice: 0.879829
[08:46:10.988] iteration 300 : loss : 1.162503, loss_ce: 2.297346, loss_dice: 0.878793
[08:46:11.084] iteration 301 : loss : 1.182430, loss_ce: 2.385649, loss_dice: 0.881625
[08:46:11.170] iteration 302 : loss : 1.126148, loss_ce: 2.124041, loss_dice: 0.876675
[08:46:11.254] iteration 303 : loss : 1.142233, loss_ce: 2.184042, loss_dice: 0.881781
[08:46:11.337] iteration 304 : loss : 1.104241, loss_ce: 2.004581, loss_dice: 0.879156
[08:46:11.420] iteration 305 : loss : 1.094031, loss_ce: 1.944103, loss_dice: 0.881513
[08:46:11.504] iteration 306 : loss : 1.124272, loss_ce: 2.066928, loss_dice: 0.888609
[08:46:11.593] iteration 307 : loss : 1.208647, loss_ce: 2.517162, loss_dice: 0.881519
[08:46:11.675] iteration 308 : loss : 1.173734, loss_ce: 2.366452, loss_dice: 0.875555
[08:46:11.759] iteration 309 : loss : 1.132788, loss_ce: 2.148843, loss_dice: 0.878774
[08:46:11.844] iteration 310 : loss : 1.109374, loss_ce: 2.026121, loss_dice: 0.880188
[08:46:11.927] iteration 311 : loss : 1.120757, loss_ce: 2.251893, loss_dice: 0.837973
[08:46:12.008] iteration 312 : loss : 1.063852, loss_ce: 2.057158, loss_dice: 0.815525
[08:46:12.091] iteration 313 : loss : 1.005111, loss_ce: 1.719903, loss_dice: 0.826413
[08:46:12.174] iteration 314 : loss : 1.258248, loss_ce: 2.743162, loss_dice: 0.887019
[08:46:12.257] iteration 315 : loss : 1.181569, loss_ce: 2.534766, loss_dice: 0.843270
[08:46:12.340] iteration 316 : loss : 1.176619, loss_ce: 2.583059, loss_dice: 0.825009
[08:46:12.421] iteration 317 : loss : 1.272593, loss_ce: 2.986758, loss_dice: 0.844052
[08:46:12.503] iteration 318 : loss : 1.232424, loss_ce: 2.808085, loss_dice: 0.838509
[08:46:12.585] iteration 319 : loss : 1.047668, loss_ce: 2.111090, loss_dice: 0.781813
[08:46:12.667] iteration 320 : loss : 1.163520, loss_ce: 2.487055, loss_dice: 0.832636
[08:46:12.757] iteration 321 : loss : 1.055457, loss_ce: 2.120979, loss_dice: 0.789077
[08:46:12.838] iteration 322 : loss : 1.166691, loss_ce: 2.309984, loss_dice: 0.880868
[08:46:12.920] iteration 323 : loss : 1.077580, loss_ce: 2.235141, loss_dice: 0.788190
[08:46:13.002] iteration 324 : loss : 1.070378, loss_ce: 2.009325, loss_dice: 0.835642
[08:46:13.087] iteration 325 : loss : 1.015143, loss_ce: 1.933689, loss_dice: 0.785506
[08:46:13.170] iteration 326 : loss : 1.052170, loss_ce: 2.129315, loss_dice: 0.782883
[08:46:13.252] iteration 327 : loss : 1.180454, loss_ce: 2.578461, loss_dice: 0.830953
[08:46:13.334] iteration 328 : loss : 1.128191, loss_ce: 2.332906, loss_dice: 0.827012
[08:46:13.416] iteration 329 : loss : 1.066530, loss_ce: 1.881656, loss_dice: 0.862749
[08:46:13.497] iteration 330 : loss : 1.033310, loss_ce: 2.055617, loss_dice: 0.777733
[08:46:13.579] iteration 331 : loss : 1.026206, loss_ce: 1.985654, loss_dice: 0.786345
[08:46:13.659] iteration 332 : loss : 1.022196, loss_ce: 1.981855, loss_dice: 0.782282
[08:46:13.744] iteration 333 : loss : 1.025869, loss_ce: 1.802736, loss_dice: 0.831652
[08:46:13.826] iteration 334 : loss : 1.055207, loss_ce: 1.933575, loss_dice: 0.835616
[08:46:13.931] iteration 335 : loss : 1.033830, loss_ce: 1.843142, loss_dice: 0.831502
[08:46:14.015] iteration 336 : loss : 1.260234, loss_ce: 2.764612, loss_dice: 0.884139
[08:46:14.098] iteration 337 : loss : 1.013925, loss_ce: 1.729257, loss_dice: 0.835092
[08:46:14.181] iteration 338 : loss : 1.169424, loss_ce: 2.317344, loss_dice: 0.882444
[08:46:14.264] iteration 339 : loss : 1.013737, loss_ce: 1.941944, loss_dice: 0.781685
[08:46:14.345] iteration 340 : loss : 1.008352, loss_ce: 1.866046, loss_dice: 0.793929
[08:46:14.439] iteration 341 : loss : 1.125074, loss_ce: 2.107897, loss_dice: 0.879369
[08:46:14.521] iteration 342 : loss : 0.964441, loss_ce: 1.651650, loss_dice: 0.792639
[08:46:14.603] iteration 343 : loss : 1.017923, loss_ce: 1.946184, loss_dice: 0.785858
[08:46:14.685] iteration 344 : loss : 1.080320, loss_ce: 1.889130, loss_dice: 0.878118
[08:46:14.767] iteration 345 : loss : 1.099724, loss_ce: 2.166251, loss_dice: 0.833092
[08:46:14.847] iteration 346 : loss : 1.056300, loss_ce: 1.946362, loss_dice: 0.833784
[08:46:14.930] iteration 347 : loss : 1.124874, loss_ce: 2.306238, loss_dice: 0.829533
[08:46:15.011] iteration 348 : loss : 1.110299, loss_ce: 2.235805, loss_dice: 0.828923
[08:46:15.094] iteration 349 : loss : 1.042279, loss_ce: 2.087771, loss_dice: 0.780905
[08:46:15.176] iteration 350 : loss : 1.022050, loss_ce: 1.992998, loss_dice: 0.779313
[08:46:15.258] iteration 351 : loss : 1.019278, loss_ce: 1.989307, loss_dice: 0.776771
[08:46:15.343] iteration 352 : loss : 0.994221, loss_ce: 1.828715, loss_dice: 0.785597
[08:46:15.425] iteration 353 : loss : 1.108958, loss_ce: 2.233728, loss_dice: 0.827765
[08:46:15.506] iteration 354 : loss : 1.037202, loss_ce: 1.861389, loss_dice: 0.831155
[08:46:15.588] iteration 355 : loss : 1.175291, loss_ce: 2.520991, loss_dice: 0.838866
[08:46:15.671] iteration 356 : loss : 1.040510, loss_ce: 1.693028, loss_dice: 0.877380
[08:46:15.755] iteration 357 : loss : 1.096693, loss_ce: 1.975795, loss_dice: 0.876918
[08:46:15.838] iteration 358 : loss : 1.068198, loss_ce: 2.016570, loss_dice: 0.831105
[08:46:15.921] iteration 359 : loss : 1.086251, loss_ce: 2.086753, loss_dice: 0.836125
[08:46:16.007] iteration 360 : loss : 1.063588, loss_ce: 2.059245, loss_dice: 0.814674
[08:46:16.100] iteration 361 : loss : 1.087476, loss_ce: 1.926422, loss_dice: 0.877740
[08:46:16.183] iteration 362 : loss : 1.131389, loss_ce: 2.127405, loss_dice: 0.882386
[08:46:16.266] iteration 363 : loss : 1.056823, loss_ce: 1.937112, loss_dice: 0.836750
[08:46:16.347] iteration 364 : loss : 1.030437, loss_ce: 1.807141, loss_dice: 0.836261
[08:46:16.430] iteration 365 : loss : 1.077351, loss_ce: 2.044770, loss_dice: 0.835496
[08:46:16.511] iteration 366 : loss : 0.992897, loss_ce: 1.813673, loss_dice: 0.787703
[08:46:16.595] iteration 367 : loss : 1.296348, loss_ce: 2.921952, loss_dice: 0.889947
